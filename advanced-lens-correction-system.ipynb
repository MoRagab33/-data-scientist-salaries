{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51abf49",
   "metadata": {
    "papermill": {
     "duration": 0.006027,
     "end_time": "2026-02-21T22:28:12.273453",
     "exception": false,
     "start_time": "2026-02-21T22:28:12.267426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Advanced Lens Correction System\n",
    "\n",
    "Professional solution for Kaggle's Automatic Lens Correction competition. \n",
    "Multi-stage pipeline for correcting barrel distortion without lens profiles.\n",
    "Optimized for geometric accuracy metrics (Edge Similarity, Line Straightness).\n",
    "\n",
    "**Key Features:**\n",
    "- Intelligent distortion detection (Edge + Hough + Gradient)\n",
    "- Multi-stage geometric correction\n",
    "- Quality enhancement (CLAHE + bilateral filtering)\n",
    "- Competition-ready output (1000 images in ~12 min)\n",
    "\n",
    "**Output:** corrected_images.zip + submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3392608",
   "metadata": {
    "papermill": {
     "duration": 0.003339,
     "end_time": "2026-02-21T22:28:12.280361",
     "exception": false,
     "start_time": "2026-02-21T22:28:12.277022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 1: Notebook Metadata and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d24ad3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T22:28:12.288535Z",
     "iopub.status.busy": "2026-02-21T22:28:12.288092Z",
     "iopub.status.idle": "2026-02-21T22:28:12.296495Z",
     "shell.execute_reply": "2026-02-21T22:28:12.295767Z"
    },
    "papermill": {
     "duration": 0.014057,
     "end_time": "2026-02-21T22:28:12.297788",
     "exception": false,
     "start_time": "2026-02-21T22:28:12.283731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "‚ïë     ADVANCED LENS CORRECTION SYSTEM - PROFESSIONAL EDITION v3.1           ‚ïë\n",
      "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
      "‚ïë  ‚Ä¢ BALANCED distortion detection & correction                             ‚ïë\n",
      "‚ïë  ‚Ä¢ Optimized parameters for competition metrics                           ‚ïë\n",
      "‚ïë  ‚Ä¢ Multi-stage quality enhancement pipeline                               ‚ïë\n",
      "‚ïë  ‚Ä¢ Competition-optimized for geometric accuracy                           ‚ïë\n",
      "‚ïë  ‚Ä¢ Production-ready with comprehensive error handling                     ‚ïë\n",
      "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üèÜ AUTOMATIC LENS CORRECTION - PROFESSIONAL KAGGLE SOLUTION v3.1\n",
    "# =============================================================================\n",
    "# Competition: Kaggle - Automatic Lens Correction\n",
    "# Goal: Correct barrel distortion in raw images without lens profiles\n",
    "# Author: Professional Computer Vision Engineer\n",
    "# Date: February 2026\n",
    "# Version: 3.1 (BALANCED Mode - Optimized for Competition)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë     ADVANCED LENS CORRECTION SYSTEM - PROFESSIONAL EDITION v3.1           ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë  ‚Ä¢ BALANCED distortion detection & correction                             ‚ïë\n",
    "‚ïë  ‚Ä¢ Optimized parameters for competition metrics                           ‚ïë\n",
    "‚ïë  ‚Ä¢ Multi-stage quality enhancement pipeline                               ‚ïë\n",
    "‚ïë  ‚Ä¢ Competition-optimized for geometric accuracy                           ‚ïë\n",
    "‚ïë  ‚Ä¢ Production-ready with comprehensive error handling                     ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8080117",
   "metadata": {
    "papermill": {
     "duration": 0.003543,
     "end_time": "2026-02-21T22:28:12.304767",
     "exception": false,
     "start_time": "2026-02-21T22:28:12.301224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 2: Import Libraries and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fff2bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T22:28:12.312719Z",
     "iopub.status.busy": "2026-02-21T22:28:12.312234Z",
     "iopub.status.idle": "2026-02-21T22:28:14.735656Z",
     "shell.execute_reply": "2026-02-21T22:28:14.734783Z"
    },
    "papermill": {
     "duration": 2.429003,
     "end_time": "2026-02-21T22:28:14.737183",
     "exception": false,
     "start_time": "2026-02-21T22:28:12.308180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenCV Version: 4.12.0\n",
      "‚úÖ NumPy Version: 2.0.2\n",
      "‚úÖ Scikit-image Version: 0.25.2\n",
      "‚úÖ CPU Cores Available: 4\n",
      "‚úÖ RAM Available: 30.10 GB\n",
      "\n",
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üìö IMPORT LIBRARIES\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import warnings\n",
    "import multiprocessing\n",
    "import psutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from skimage import exposure, filters, morphology, measure, feature\n",
    "from scipy import ndimage, signal\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check versions\n",
    "print(f\"‚úÖ OpenCV Version: {cv2.__version__}\")\n",
    "print(f\"‚úÖ NumPy Version: {np.__version__}\")\n",
    "print(f\"‚úÖ Scikit-image Version: {skimage.__version__}\")\n",
    "print(f\"‚úÖ CPU Cores Available: {multiprocessing.cpu_count()}\")\n",
    "print(f\"‚úÖ RAM Available: {psutil.virtual_memory().available / (1024**3):.2f} GB\")\n",
    "\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb7c673",
   "metadata": {
    "papermill": {
     "duration": 0.003596,
     "end_time": "2026-02-21T22:28:14.744949",
     "exception": false,
     "start_time": "2026-02-21T22:28:14.741353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 3: Path Configuration and Auto-Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48d34d6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-21T22:28:14.753973Z",
     "iopub.status.busy": "2026-02-21T22:28:14.753318Z",
     "iopub.status.idle": "2026-02-21T22:28:15.451048Z",
     "shell.execute_reply": "2026-02-21T22:28:15.450104Z"
    },
    "papermill": {
     "duration": 0.704024,
     "end_time": "2026-02-21T22:28:15.452538",
     "exception": false,
     "start_time": "2026-02-21T22:28:14.748514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîç CONFIGURING PATHS AND ENVIRONMENT\n",
      "============================================================\n",
      "‚úÖ Competition path: /kaggle/input/automatic-lens-correction\n",
      "‚úÖ Train folder found: /kaggle/input/automatic-lens-correction/lens-correction-train-cleaned\n",
      "‚úÖ Test folder found: /kaggle/input/automatic-lens-correction/test-originals\n",
      "‚úÖ Output folder created: /kaggle/working/corrected_images\n",
      "üì∏ Total test images found: 1000\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üîç AUTO-DETECT PATHS AND CONFIGURE ENVIRONMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîç CONFIGURING PATHS AND ENVIRONMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def setup_paths():\n",
    "    \"\"\"\n",
    "    Automatically detect and configure all necessary paths\n",
    "    \"\"\"\n",
    "    base_input = '/kaggle/input'\n",
    "    \n",
    "    # Find competition folder\n",
    "    competition_folders = [f for f in os.listdir(base_input) \n",
    "                          if 'automatic-lens-correction' in f.lower()]\n",
    "    \n",
    "    if not competition_folders:\n",
    "        raise Exception(\"‚ùå Competition data not found! Please add the competition input.\")\n",
    "    \n",
    "    COMP_PATH = os.path.join(base_input, competition_folders[0])\n",
    "    print(f\"‚úÖ Competition path: {COMP_PATH}\")\n",
    "    \n",
    "    # Find train and test folders\n",
    "    contents = os.listdir(COMP_PATH)\n",
    "    TRAIN_PATH = None\n",
    "    TEST_PATH = None\n",
    "    \n",
    "    # Look for test folder (prioritize folders containing images)\n",
    "    for item in contents:\n",
    "        item_path = os.path.join(COMP_PATH, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            files = os.listdir(item_path)\n",
    "            if files and any(f.endswith(('.jpg', '.png', '.jpeg')) for f in files):\n",
    "                if 'test' in item.lower() or 'original' in item.lower():\n",
    "                    TEST_PATH = item_path\n",
    "                    print(f\"‚úÖ Test folder found: {TEST_PATH}\")\n",
    "                elif 'train' in item.lower():\n",
    "                    TRAIN_PATH = item_path\n",
    "                    print(f\"‚úÖ Train folder found: {TRAIN_PATH}\")\n",
    "    \n",
    "    # Fallback: use any folder with images as test folder\n",
    "    if not TEST_PATH:\n",
    "        for item in contents:\n",
    "            item_path = os.path.join(COMP_PATH, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                files = os.listdir(item_path)\n",
    "                if files and any(f.endswith(('.jpg', '.png', '.jpeg')) for f in files):\n",
    "                    TEST_PATH = item_path\n",
    "                    print(f\"‚úÖ Using as test folder: {TEST_PATH}\")\n",
    "                    break\n",
    "    \n",
    "    if not TEST_PATH:\n",
    "        raise Exception(\"‚ùå Could not find test images folder!\")\n",
    "    \n",
    "    # Create output directory\n",
    "    OUTPUT_PATH = '/kaggle/working/corrected_images'\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "    print(f\"‚úÖ Output folder created: {OUTPUT_PATH}\")\n",
    "    \n",
    "    # Count test images\n",
    "    test_files = []\n",
    "    for ext in ['*.jpg', '*.png', '*.jpeg']:\n",
    "        test_files.extend(Path(TEST_PATH).glob(ext))\n",
    "    \n",
    "    print(f\"üì∏ Total test images found: {len(test_files)}\")\n",
    "    \n",
    "    return COMP_PATH, TRAIN_PATH, TEST_PATH, OUTPUT_PATH, test_files\n",
    "\n",
    "# Execute path setup\n",
    "COMP_PATH, TRAIN_PATH, TEST_PATH, OUTPUT_PATH, TEST_FILES = setup_paths()\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e26268",
   "metadata": {
    "papermill": {
     "duration": 0.003687,
     "end_time": "2026-02-21T22:28:15.460229",
     "exception": false,
     "start_time": "2026-02-21T22:28:15.456542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 4: Advanced Lens Correction Engine (AGGRESSIVE MODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674ff08c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T22:28:15.468878Z",
     "iopub.status.busy": "2026-02-21T22:28:15.468625Z",
     "iopub.status.idle": "2026-02-21T22:28:15.489844Z",
     "shell.execute_reply": "2026-02-21T22:28:15.489294Z"
    },
    "papermill": {
     "duration": 0.02734,
     "end_time": "2026-02-21T22:28:15.491139",
     "exception": false,
     "start_time": "2026-02-21T22:28:15.463799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üîß ADVANCED LENS CORRECTION ENGINE - BALANCED MODE v3.1\n",
    "# =============================================================================\n",
    "\n",
    "class AdvancedLensCorrector:\n",
    "    \"\"\"\n",
    "    Professional lens correction system with BALANCED parameters\n",
    "    Optimized for competition metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"\n",
    "        Initialize with BALANCED configuration\n",
    "        \"\"\"\n",
    "        # BALANCED configuration - NOT TOO AGGRESSIVE\n",
    "        self.config = {\n",
    "            # Edge detection parameters\n",
    "            'canny_threshold1': 40,\n",
    "            'canny_threshold2': 100,\n",
    "            'hough_threshold': 70,\n",
    "            'min_line_length': 70,\n",
    "            'max_line_gap': 12,\n",
    "            \n",
    "            # Enhancement parameters\n",
    "            'clahe_clip_limit': 2.5,\n",
    "            'clahe_grid_size': (8, 8),\n",
    "            'bilateral_diameter': 9,\n",
    "            'bilateral_sigma_color': 75,\n",
    "            'bilateral_sigma_space': 75,\n",
    "            \n",
    "            # BALANCED distortion parameters\n",
    "            'distortion_k1_factor': 0.15,\n",
    "            'distortion_k2_factor': 0.02,\n",
    "            'distortion_k3_factor': 0.002,\n",
    "            'line_correction_threshold': 0.4,\n",
    "            'line_correction_boost': 1.5,\n",
    "            \n",
    "            # Output quality\n",
    "            'output_quality': 100,\n",
    "        }\n",
    "        \n",
    "        if config:\n",
    "            self.config.update(config)\n",
    "            \n",
    "        self.stats = {'processed': 0, 'failed': 0}\n",
    "        print(\"‚úÖ AdvancedLensCorrector - BALANCED MODE initialized\")\n",
    "    \n",
    "    def detect_distortion_parameters(self, image):\n",
    "        \"\"\"\n",
    "        Analyze image and estimate optimal distortion parameters\n",
    "        \"\"\"\n",
    "        # Convert to grayscale\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        # Multi-scale edge detection\n",
    "        edges_fine = cv2.Canny(gray, 20, 60)\n",
    "        edges_medium = cv2.Canny(gray, 40, 100)\n",
    "        edges_coarse = cv2.Canny(gray, 60, 140)\n",
    "        \n",
    "        # Combine edges\n",
    "        edges = cv2.bitwise_or(edges_fine, edges_medium)\n",
    "        edges = cv2.bitwise_or(edges, edges_coarse)\n",
    "        \n",
    "        # Detect lines\n",
    "        lines = cv2.HoughLinesP(\n",
    "            edges, \n",
    "            rho=1, \n",
    "            theta=np.pi/180, \n",
    "            threshold=self.config['hough_threshold'],\n",
    "            minLineLength=self.config['min_line_length'],\n",
    "            maxLineGap=self.config['max_line_gap']\n",
    "        )\n",
    "        \n",
    "        if lines is not None and len(lines) > 5:\n",
    "            return self._estimate_from_lines(lines, gray.shape)\n",
    "        else:\n",
    "            return self._estimate_from_gradient(gray)\n",
    "    \n",
    "    def _estimate_from_lines(self, lines, image_shape):\n",
    "        \"\"\"\n",
    "        Estimate distortion parameters from detected lines\n",
    "        \"\"\"\n",
    "        angles = []\n",
    "        lengths = []\n",
    "        \n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n",
    "            length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            angles.append(angle)\n",
    "            lengths.append(length)\n",
    "        \n",
    "        # Weight by length\n",
    "        weights = np.array(lengths) / (np.sum(lengths) + 1e-6)\n",
    "        \n",
    "        # Calculate distortion factor\n",
    "        h, w = image_shape\n",
    "        angle_std = np.std(angles)\n",
    "        distortion_factor = angle_std / 45.0\n",
    "        \n",
    "        # Scale by image size\n",
    "        scale = np.sqrt(h * w) / 1000\n",
    "        \n",
    "        # Calculate parameters\n",
    "        k1 = self.config['distortion_k1_factor'] * distortion_factor * scale\n",
    "        k2 = self.config['distortion_k2_factor'] * distortion_factor * scale\n",
    "        k3 = self.config['distortion_k3_factor'] * distortion_factor * scale\n",
    "        \n",
    "        return {'k1': k1, 'k2': k2, 'k3': k3}\n",
    "    \n",
    "    def _estimate_from_gradient(self, gray):\n",
    "        \"\"\"\n",
    "        Estimate distortion parameters from gradient analysis\n",
    "        \"\"\"\n",
    "        # Calculate gradients\n",
    "        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n",
    "        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)\n",
    "        \n",
    "        # Calculate gradient magnitude and direction\n",
    "        magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "        angle = np.arctan2(grad_y, grad_x)\n",
    "        \n",
    "        h, w = gray.shape\n",
    "        center = np.array([h/2, w/2])\n",
    "        \n",
    "        y, x = np.indices((h, w))\n",
    "        r = np.sqrt((x - center[1])**2 + (y - center[0])**2)\n",
    "        r_max = np.sqrt(center[0]**2 + center[1]**2)\n",
    "        r_norm = r / r_max\n",
    "        \n",
    "        # Estimate from angle variation\n",
    "        angle_variation = np.std(angle[r_norm > 0.4])\n",
    "        k1 = angle_variation * 1.5 / np.pi\n",
    "        k2 = k1 / 10\n",
    "        k3 = k1 / 100\n",
    "        \n",
    "        return {'k1': k1, 'k2': k2, 'k3': k3}\n",
    "    \n",
    "    def apply_aggressive_correction(self, image, params):\n",
    "        \"\"\"\n",
    "        Apply geometric distortion correction\n",
    "        \"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        # Camera matrix\n",
    "        camera_matrix = np.array([\n",
    "            [w, 0, w/2],\n",
    "            [0, h, h/2],\n",
    "            [0, 0, 1]\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        # Distortion coefficients\n",
    "        dist_coeffs = np.array([\n",
    "            params['k1'], \n",
    "            params['k2'], \n",
    "            0, 0, \n",
    "            params['k3']\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        # Get optimal new camera matrix\n",
    "        new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(\n",
    "            camera_matrix, \n",
    "            dist_coeffs, \n",
    "            (w, h), \n",
    "            alpha=1, \n",
    "            newImgSize=(w, h)\n",
    "        )\n",
    "        \n",
    "        # Apply correction\n",
    "        corrected = cv2.undistort(\n",
    "            image, \n",
    "            camera_matrix, \n",
    "            dist_coeffs, \n",
    "            None, \n",
    "            new_camera_matrix\n",
    "        )\n",
    "        \n",
    "        # Crop and resize if needed\n",
    "        x, y, w_roi, h_roi = roi\n",
    "        if w_roi > 0 and h_roi > 0:\n",
    "            corrected = corrected[y:y+h_roi, x:x+w_roi]\n",
    "            corrected = cv2.resize(corrected, (w, h))\n",
    "        \n",
    "        return corrected\n",
    "    \n",
    "    def enhance_line_straightness_aggressive(self, image):\n",
    "        \"\"\"\n",
    "        Line straightening correction\n",
    "        \"\"\"\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        # Detect edges\n",
    "        edges = cv2.Canny(gray, 20, 60, apertureSize=3)\n",
    "        \n",
    "        # Detect lines\n",
    "        lines = cv2.HoughLinesP(\n",
    "            edges, \n",
    "            rho=1, \n",
    "            theta=np.pi/180, \n",
    "            threshold=40,\n",
    "            minLineLength=40, \n",
    "            maxLineGap=10\n",
    "        )\n",
    "        \n",
    "        if lines is None or len(lines) < 3:\n",
    "            return image\n",
    "        \n",
    "        # Apply additional correction if needed\n",
    "        params = self.detect_distortion_parameters(gray)\n",
    "        params['k1'] *= self.config['line_correction_boost']\n",
    "        params['k2'] *= self.config['line_correction_boost']\n",
    "        \n",
    "        return self.apply_aggressive_correction(image, params)\n",
    "    \n",
    "    def enhance_image_quality_aggressive(self, image):\n",
    "        \"\"\"\n",
    "        Quality enhancement\n",
    "        \"\"\"\n",
    "        result = image.copy()\n",
    "        \n",
    "        if len(image.shape) == 3:\n",
    "            # Convert to LAB\n",
    "            lab = cv2.cvtColor(result, cv2.COLOR_BGR2LAB)\n",
    "            l, a, b = cv2.split(lab)\n",
    "            \n",
    "            # Apply CLAHE\n",
    "            clahe = cv2.createCLAHE(\n",
    "                clipLimit=self.config['clahe_clip_limit'],\n",
    "                tileGridSize=self.config['clahe_grid_size']\n",
    "            )\n",
    "            l_enhanced = clahe.apply(l)\n",
    "            \n",
    "            # Merge\n",
    "            lab_enhanced = cv2.merge([l_enhanced, a, b])\n",
    "            result = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)\n",
    "            \n",
    "            # Bilateral filter\n",
    "            result = cv2.bilateralFilter(\n",
    "                result,\n",
    "                d=self.config['bilateral_diameter'],\n",
    "                sigmaColor=self.config['bilateral_sigma_color'],\n",
    "                sigmaSpace=self.config['bilateral_sigma_space']\n",
    "            )\n",
    "            \n",
    "            # Sharpening\n",
    "            kernel = np.array([\n",
    "                [-1, -1, -1],\n",
    "                [-1, 9, -1],\n",
    "                [-1, -1, -1]\n",
    "            ])\n",
    "            result = cv2.filter2D(result, -1, kernel)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # ===== MAIN PROCESSING FUNCTION =====\n",
    "    def process_single_image_balanced(self, image_path):\n",
    "        \"\"\"\n",
    "        Complete BALANCED processing pipeline\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Read image\n",
    "            image = cv2.imread(str(image_path))\n",
    "            if image is None:\n",
    "                self.stats['failed'] += 1\n",
    "                return None\n",
    "            \n",
    "            # Step 1: Detect distortion\n",
    "            params = self.detect_distortion_parameters(image)\n",
    "            \n",
    "            # Step 2: Apply correction\n",
    "            corrected = self.apply_aggressive_correction(image, params)\n",
    "            \n",
    "            # Step 3: Line straightening\n",
    "            line_corrected = self.enhance_line_straightness_aggressive(corrected)\n",
    "            \n",
    "            # Step 4: Quality enhancement\n",
    "            enhanced = self.enhance_image_quality_aggressive(line_corrected)\n",
    "            \n",
    "            self.stats['processed'] += 1\n",
    "            return enhanced\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing image: {e}\")\n",
    "            self.stats['failed'] += 1\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14890666",
   "metadata": {
    "papermill": {
     "duration": 0.003452,
     "end_time": "2026-02-21T22:28:15.498498",
     "exception": false,
     "start_time": "2026-02-21T22:28:15.495046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 5: Submission File Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1285bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T22:28:15.506996Z",
     "iopub.status.busy": "2026-02-21T22:28:15.506666Z",
     "iopub.status.idle": "2026-02-21T22:28:15.521473Z",
     "shell.execute_reply": "2026-02-21T22:28:15.520768Z"
    },
    "papermill": {
     "duration": 0.021012,
     "end_time": "2026-02-21T22:28:15.523053",
     "exception": false,
     "start_time": "2026-02-21T22:28:15.502041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üì¶ SUBMISSION FILE GENERATOR\n",
    "# =============================================================================\n",
    "\n",
    "class SubmissionGenerator:\n",
    "    \"\"\"\n",
    "    Generate competition submission files with multiple options\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_path):\n",
    "        self.output_path = Path(output_path)\n",
    "        self.submission_file = '/kaggle/working/submission.csv'\n",
    "        self.zip_file = '/kaggle/working/corrected_images.zip'\n",
    "        self.final_zip = '/kaggle/working/corrected_images_final.zip'\n",
    "        \n",
    "    def create_submission_csv(self):\n",
    "        \"\"\"\n",
    "        Create submission.csv file\n",
    "        \"\"\"\n",
    "        corrected_images = list(self.output_path.glob('*.*'))\n",
    "        \n",
    "        if not corrected_images:\n",
    "            print(\"‚ùå No corrected images found!\")\n",
    "            return False\n",
    "        \n",
    "        submission_data = []\n",
    "        for img_path in corrected_images:\n",
    "            image_id = img_path.stem\n",
    "            submission_data.append([image_id, 0.0])\n",
    "        \n",
    "        submission_df = pd.DataFrame(\n",
    "            submission_data, \n",
    "            columns=['image_id', 'score']\n",
    "        )\n",
    "        submission_df.to_csv(self.submission_file, index=False)\n",
    "        \n",
    "        print(f\"‚úÖ Created submission.csv with {len(submission_data)} images\")\n",
    "        return True\n",
    "    \n",
    "    def create_zip_archive(self, quality=95):\n",
    "        \"\"\"\n",
    "        Create zip archive with specified quality\n",
    "        \"\"\"\n",
    "        corrected_images = list(self.output_path.glob('*.*'))\n",
    "        \n",
    "        if not corrected_images:\n",
    "            print(\"‚ùå No corrected images found!\")\n",
    "            return False\n",
    "        \n",
    "        if quality < 100:\n",
    "            # Compress with specified quality\n",
    "            temp_dir = '/kaggle/working/temp_compressed'\n",
    "            os.makedirs(temp_dir, exist_ok=True)\n",
    "            \n",
    "            for img_path in tqdm(corrected_images, desc=\"Compressing\"):\n",
    "                img = cv2.imread(str(img_path))\n",
    "                out_path = os.path.join(temp_dir, img_path.name)\n",
    "                cv2.imwrite(out_path, img, [cv2.IMWRITE_JPEG_QUALITY, quality])\n",
    "            \n",
    "            with zipfile.ZipFile(self.zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "                for img_path in Path(temp_dir).glob('*.jpg'):\n",
    "                    zipf.write(img_path, arcname=img_path.name)\n",
    "        else:\n",
    "            # No compression\n",
    "            with zipfile.ZipFile(self.zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "                for img_path in tqdm(corrected_images, desc=\"Zipping\"):\n",
    "                    zipf.write(img_path, arcname=img_path.name)\n",
    "        \n",
    "        size_mb = os.path.getsize(self.zip_file) / (1024 * 1024)\n",
    "        print(f\"‚úÖ Created ZIP: {size_mb:.2f} MB (Quality: {quality}%)\")\n",
    "        return True\n",
    "    \n",
    "    def create_high_quality_zip(self):\n",
    "        \"\"\"\n",
    "        Create maximum quality zip (100%)\n",
    "        \"\"\"\n",
    "        corrected_images = list(self.output_path.glob('*.*'))\n",
    "        \n",
    "        if not corrected_images:\n",
    "            print(\"‚ùå No corrected images found!\")\n",
    "            return False\n",
    "        \n",
    "        # Create fixed folder\n",
    "        fixed_folder = '/kaggle/working/corrected_images_fixed'\n",
    "        os.makedirs(fixed_folder, exist_ok=True)\n",
    "        \n",
    "        # Save with maximum quality\n",
    "        for img_path in tqdm(corrected_images, desc=\"Fixing images\"):\n",
    "            img = cv2.imread(str(img_path))\n",
    "            out_path = os.path.join(fixed_folder, img_path.name)\n",
    "            cv2.imwrite(out_path, img, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "        \n",
    "        # Create zip\n",
    "        with zipfile.ZipFile(self.final_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for img_path in tqdm(Path(fixed_folder).glob('*.jpg'), desc=\"Zipping\"):\n",
    "                zipf.write(img_path, arcname=img_path.name)\n",
    "        \n",
    "        size_mb = os.path.getsize(self.final_zip) / (1024 * 1024)\n",
    "        print(f\"‚úÖ High Quality ZIP: {size_mb:.2f} MB\")\n",
    "        return True\n",
    "    \n",
    "    def get_file_info(self):\n",
    "        \"\"\"Return information about generated files\"\"\"\n",
    "        info = {}\n",
    "        \n",
    "        if os.path.exists(self.submission_file):\n",
    "            info['submission'] = {\n",
    "                'size': os.path.getsize(self.submission_file),\n",
    "                'rows': len(pd.read_csv(self.submission_file))\n",
    "            }\n",
    "        \n",
    "        if os.path.exists(self.zip_file):\n",
    "            info['zip'] = {\n",
    "                'size_mb': os.path.getsize(self.zip_file) / (1024 * 1024),\n",
    "                'path': self.zip_file\n",
    "            }\n",
    "        \n",
    "        if os.path.exists(self.final_zip):\n",
    "            info['final_zip'] = {\n",
    "                'size_mb': os.path.getsize(self.final_zip) / (1024 * 1024),\n",
    "                'path': self.final_zip\n",
    "            }\n",
    "        \n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399aefd8",
   "metadata": {
    "papermill": {
     "duration": 0.004599,
     "end_time": "2026-02-21T22:28:15.532224",
     "exception": false,
     "start_time": "2026-02-21T22:28:15.527625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 6: Main Execution Function (AGGRESSIVE MODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774fca66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T22:28:15.542386Z",
     "iopub.status.busy": "2026-02-21T22:28:15.541971Z",
     "iopub.status.idle": "2026-02-21T22:45:18.690685Z",
     "shell.execute_reply": "2026-02-21T22:45:18.689770Z"
    },
    "papermill": {
     "duration": 1023.155736,
     "end_time": "2026-02-21T22:45:18.692309",
     "exception": false,
     "start_time": "2026-02-21T22:28:15.536573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ STARTING BALANCED LENS CORRECTION PIPELINE v3.1\n",
      "================================================================================\n",
      "üì∏ Found 1000 test images to process\n",
      "\n",
      "‚öôÔ∏è Initializing BALANCED correction engine...\n",
      "‚úÖ AdvancedLensCorrector - BALANCED MODE initialized\n",
      "\n",
      "üñºÔ∏è Processing images with BALANCED parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  10%|‚ñà         | 100/1000 [01:21<12:27,  1.20img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 100/1000 | Rate: 1.23 img/s | Success: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  20%|‚ñà‚ñà        | 200/1000 [02:42<11:26,  1.16img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 200/1000 | Rate: 1.23 img/s | Success: 200/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  30%|‚ñà‚ñà‚ñà       | 300/1000 [04:00<09:51,  1.18img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 300/1000 | Rate: 1.25 img/s | Success: 300/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  40%|‚ñà‚ñà‚ñà‚ñà      | 400/1000 [05:21<07:58,  1.25img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 400/1000 | Rate: 1.24 img/s | Success: 400/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 500/1000 [06:36<06:57,  1.20img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 500/1000 | Rate: 1.26 img/s | Success: 500/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 600/1000 [07:57<04:47,  1.39img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 600/1000 | Rate: 1.26 img/s | Success: 600/600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 700/1000 [09:14<04:10,  1.20img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 700/1000 | Rate: 1.26 img/s | Success: 700/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 800/1000 [10:33<02:32,  1.31img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 800/1000 | Rate: 1.26 img/s | Success: 800/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 900/1000 [11:50<01:20,  1.24img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 900/1000 | Rate: 1.27 img/s | Success: 900/900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [13:11<00:00,  1.26img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 1000/1000 | Rate: 1.26 img/s | Success: 1000/1000\n",
      "\n",
      "================================================================================\n",
      "‚úÖ BALANCED PROCESSING COMPLETE\n",
      "================================================================================\n",
      "\n",
      "    ‚è±Ô∏è  Total time:     791.91 seconds (13.20 minutes)\n",
      "    üì∏ Total images:    1000\n",
      "    ‚úÖ Successful:       1000\n",
      "    ‚ùå Failed:           0\n",
      "    ‚ö° Average rate:     1.26 img/s\n",
      "    \n",
      "\n",
      "üì¶ Generating submission files...\n",
      "‚úÖ Created submission.csv with 1000 images\n",
      "\n",
      "üì¶ Creating Standard ZIP (95% quality)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compressing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:49<00:00, 20.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created ZIP: 957.01 MB (Quality: 95%)\n",
      "\n",
      "üì¶ Creating High Quality ZIP (100% quality)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fixing images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:57<00:00, 17.40it/s]\n",
      "Zipping: 1000it [01:22, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ High Quality ZIP: 2046.92 MB\n",
      "\n",
      "================================================================================\n",
      "üéØ SUBMISSION FILES READY\n",
      "================================================================================\n",
      "üì¶ Standard ZIP (95%): 957.01 MB\n",
      "üì¶ High Quality ZIP (100%): 2046.92 MB\n",
      "üìÑ submission.csv: 1000 entries\n",
      "\n",
      "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n",
      "NEXT STEPS:\n",
      "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n",
      "\n",
      "    1Ô∏è‚É£  Try High Quality ZIP first (100% quality)\n",
      "    2Ô∏è‚É£  If too large (>500MB), use Standard ZIP (95% quality)\n",
      "    3Ô∏è‚É£  Upload to: https://bounty.autohdr.com\n",
      "    4Ô∏è‚É£  Download submission.csv and upload to Kaggle\n",
      "    \n",
      "    ‚è∞ Deadline: Today before midnight\n",
      "    üèÜ Target Score: >0.80\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üöÄ MAIN EXECUTION FUNCTION - BALANCED MODE v3.1\n",
    "# =============================================================================\n",
    "\n",
    "def main_balanced():\n",
    "    \"\"\"\n",
    "    Main execution with BALANCED correction parameters\n",
    "    \"\"\"\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üöÄ STARTING BALANCED LENS CORRECTION PIPELINE v3.1\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get test files\n",
    "    test_files = TEST_FILES\n",
    "    print(f\"üì∏ Found {len(test_files)} test images to process\")\n",
    "    \n",
    "    if len(test_files) == 0:\n",
    "        print(\"‚ùå No test images found! Exiting...\")\n",
    "        return\n",
    "    \n",
    "    # Initialize processor\n",
    "    print(\"\\n‚öôÔ∏è Initializing BALANCED correction engine...\")\n",
    "    corrector = AdvancedLensCorrector()\n",
    "    \n",
    "    # Process images with progress bar\n",
    "    print(\"\\nüñºÔ∏è Processing images with BALANCED parameters...\")\n",
    "    successful = 0\n",
    "    \n",
    "    for i, test_file in enumerate(tqdm(test_files, desc=\"Progress\", unit=\"img\")):\n",
    "        try:\n",
    "            # Process single image with balanced pipeline\n",
    "            corrected = corrector.process_single_image_balanced(test_file)\n",
    "            \n",
    "            if corrected is not None:\n",
    "                # Save corrected image\n",
    "                output_path = os.path.join(OUTPUT_PATH, test_file.name)\n",
    "                cv2.imwrite(output_path, corrected, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "                successful += 1\n",
    "            \n",
    "            # Show progress every 100 images\n",
    "            if (i + 1) % 100 == 0:\n",
    "                elapsed = (datetime.now() - start_time).total_seconds()\n",
    "                rate = (i + 1) / elapsed\n",
    "                print(f\"\\nüìä Progress: {i + 1}/{len(test_files)} | \"\n",
    "                      f\"Rate: {rate:.2f} img/s | \"\n",
    "                      f\"Success: {successful}/{i + 1}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error on {test_file.name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Final statistics\n",
    "    elapsed_time = (datetime.now() - start_time).total_seconds()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ BALANCED PROCESSING COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\"\"\n",
    "    ‚è±Ô∏è  Total time:     {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\n",
    "    üì∏ Total images:    {len(test_files)}\n",
    "    ‚úÖ Successful:       {successful}\n",
    "    ‚ùå Failed:           {len(test_files) - successful}\n",
    "    ‚ö° Average rate:     {len(test_files)/elapsed_time:.2f} img/s\n",
    "    \"\"\")\n",
    "    \n",
    "    # Generate submission files\n",
    "    if successful > 0:\n",
    "        print(\"\\nüì¶ Generating submission files...\")\n",
    "        generator = SubmissionGenerator(OUTPUT_PATH)\n",
    "        \n",
    "        # Create submission CSV\n",
    "        generator.create_submission_csv()\n",
    "        \n",
    "        # Create standard ZIP (95% quality)\n",
    "        print(\"\\nüì¶ Creating Standard ZIP (95% quality)...\")\n",
    "        generator.create_zip_archive(quality=95)\n",
    "        \n",
    "        # Create high quality ZIP (100% quality)\n",
    "        print(\"\\nüì¶ Creating High Quality ZIP (100% quality)...\")\n",
    "        generator.create_high_quality_zip()\n",
    "        \n",
    "        # Show file info\n",
    "        info = generator.get_file_info()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üéØ SUBMISSION FILES READY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if 'zip' in info:\n",
    "            print(f\"üì¶ Standard ZIP (95%): {info['zip']['size_mb']:.2f} MB\")\n",
    "        if 'final_zip' in info:\n",
    "            print(f\"üì¶ High Quality ZIP (100%): {info['final_zip']['size_mb']:.2f} MB\")\n",
    "        if 'submission' in info:\n",
    "            print(f\"üìÑ submission.csv: {info['submission']['rows']} entries\")\n",
    "        \n",
    "        print(\"\\n\" + \"‚≠ê\"*40)\n",
    "        print(\"NEXT STEPS:\")\n",
    "        print(\"‚≠ê\"*40)\n",
    "        print(\"\"\"\n",
    "    1Ô∏è‚É£  Try High Quality ZIP first (100% quality)\n",
    "    2Ô∏è‚É£  If too large (>500MB), use Standard ZIP (95% quality)\n",
    "    3Ô∏è‚É£  Upload to: https://bounty.autohdr.com\n",
    "    4Ô∏è‚É£  Download submission.csv and upload to Kaggle\n",
    "    \n",
    "    ‚è∞ Deadline: Today before midnight\n",
    "    üèÜ Target Score: >0.80\n",
    "        \"\"\")\n",
    "\n",
    "# Execute main function\n",
    "main_balanced()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c77d3",
   "metadata": {
    "papermill": {
     "duration": 0.091053,
     "end_time": "2026-02-21T22:45:18.874285",
     "exception": false,
     "start_time": "2026-02-21T22:45:18.783232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 7: Performance Optimization & System Info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc0af81b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T22:45:19.135049Z",
     "iopub.status.busy": "2026-02-21T22:45:19.134755Z",
     "iopub.status.idle": "2026-02-21T22:45:19.165221Z",
     "shell.execute_reply": "2026-02-21T22:45:19.164371Z"
    },
    "papermill": {
     "duration": 0.119019,
     "end_time": "2026-02-21T22:45:19.166704",
     "exception": false,
     "start_time": "2026-02-21T22:45:19.047685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "‚ö° SYSTEM PERFORMANCE ANALYSIS\n",
      "============================================================\n",
      "‚úÖ CPU Cores: 4\n",
      "‚úÖ RAM Total: 31.35 GB\n",
      "‚úÖ RAM Available: 30.02 GB\n",
      "‚úÖ GPU: Tesla P100-PCIE-16GB, 16384 MiB\n",
      "\n",
      "üí° OPTIMIZATION TIPS:\n",
      "‚Ä¢ BALANCED mode enabled - optimized for competition\n",
      "‚Ä¢ Processing 1000 images in ~12-15 minutes\n",
      "‚Ä¢ Two ZIP files created: Standard (95%) and High Quality (100%)\n",
      "‚Ä¢ Monitor memory usage during processing\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ‚ö° PERFORMANCE OPTIMIZATION & SYSTEM INFORMATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚ö° SYSTEM PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# CPU Information\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "print(f\"‚úÖ CPU Cores: {cpu_count}\")\n",
    "\n",
    "# Memory Information\n",
    "memory = psutil.virtual_memory()\n",
    "print(f\"‚úÖ RAM Total: {memory.total / (1024**3):.2f} GB\")\n",
    "print(f\"‚úÖ RAM Available: {memory.available / (1024**3):.2f} GB\")\n",
    "\n",
    "# GPU Information\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        ['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], \n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úÖ GPU: {result.stdout.strip()}\")\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è GPU information not available\")\n",
    "\n",
    "print(\"\\nüí° OPTIMIZATION TIPS:\")\n",
    "print(\"‚Ä¢ BALANCED mode enabled - optimized for competition\")\n",
    "print(\"‚Ä¢ Processing 1000 images in ~12-15 minutes\")\n",
    "print(\"‚Ä¢ Two ZIP files created: Standard (95%) and High Quality (100%)\")\n",
    "print(\"‚Ä¢ Monitor memory usage during processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9262b55",
   "metadata": {
    "papermill": {
     "duration": 0.086696,
     "end_time": "2026-02-21T22:45:19.340632",
     "exception": false,
     "start_time": "2026-02-21T22:45:19.253936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 8: Verification & Diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "668d507b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T22:45:19.513965Z",
     "iopub.status.busy": "2026-02-21T22:45:19.513658Z",
     "iopub.status.idle": "2026-02-21T22:45:19.611762Z",
     "shell.execute_reply": "2026-02-21T22:45:19.610941Z"
    },
    "papermill": {
     "duration": 0.185978,
     "end_time": "2026-02-21T22:45:19.613505",
     "exception": false,
     "start_time": "2026-02-21T22:45:19.427527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "‚úÖ VERIFYING OUTPUTS\n",
      "============================================================\n",
      "\n",
      "üìÅ Working directory contents:\n",
      "  üìÑ __notebook__.ipynb\n",
      "  üìÇ corrected_images/ (1000 files)\n",
      "  üì¶ corrected_images.zip (957.01 MB)\n",
      "  üì¶ corrected_images_final.zip (2046.92 MB)\n",
      "  üìÇ corrected_images_fixed/ (1000 files)\n",
      "  üìÑ submission.csv (1000 entries)\n",
      "  üìÇ temp_compressed/ (1000 files)\n",
      "\n",
      "‚úÖ corrected_images: 1000 images\n",
      "üìù Sample: ['fe6a7f74-e126-4bb6-ae94-76e2c3792c6c_g18.jpg', '10a0779a-b9ca-4fbb-9cdf-cab54ea85eeb_g2.jpg', '10a0779a-b9ca-4fbb-9cdf-cab54ea85eeb_g10.jpg']\n",
      "\n",
      "‚úÖ submission.csv: 1000 entries\n",
      "üìù Columns: ['image_id', 'score']\n",
      "\n",
      "üì¶ ZIP files found:\n",
      "   ‚Ä¢ corrected_images.zip: 957.01 MB\n",
      "   ‚Ä¢ corrected_images_final.zip: 2046.92 MB\n",
      "\n",
      "============================================================\n",
      "üéØ READY FOR SUBMISSION!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ‚úÖ VERIFICATION & DIAGNOSTICS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ VERIFYING OUTPUTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def verify_all_outputs():\n",
    "    \"\"\"Comprehensive verification of all outputs\"\"\"\n",
    "    \n",
    "    # Check working directory\n",
    "    working_dir = '/kaggle/working'\n",
    "    print(f\"\\nüìÅ Working directory contents:\")\n",
    "    for item in sorted(os.listdir(working_dir)):\n",
    "        item_path = os.path.join(working_dir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            files = list(Path(item_path).glob('*.*'))\n",
    "            print(f\"  üìÇ {item}/ ({len(files)} files)\")\n",
    "        else:\n",
    "            size = os.path.getsize(item_path) / (1024 * 1024) if item.endswith('.zip') else 0\n",
    "            if item.endswith('.zip'):\n",
    "                print(f\"  üì¶ {item} ({size:.2f} MB)\")\n",
    "            elif item.endswith('.csv'):\n",
    "                try:\n",
    "                    df = pd.read_csv(item_path)\n",
    "                    print(f\"  üìÑ {item} ({len(df)} entries)\")\n",
    "                except:\n",
    "                    print(f\"  üìÑ {item}\")\n",
    "            else:\n",
    "                print(f\"  üìÑ {item}\")\n",
    "    \n",
    "    # Check corrected_images folder\n",
    "    img_folder = Path('/kaggle/working/corrected_images')\n",
    "    if img_folder.exists():\n",
    "        images = list(img_folder.glob('*.jpg'))\n",
    "        print(f\"\\n‚úÖ corrected_images: {len(images)} images\")\n",
    "        if images:\n",
    "            print(f\"üìù Sample: {[f.name for f in images[:3]]}\")\n",
    "    \n",
    "    # Check submission files\n",
    "    sub_file = '/kaggle/working/submission.csv'\n",
    "    if os.path.exists(sub_file):\n",
    "        try:\n",
    "            df = pd.read_csv(sub_file)\n",
    "            print(f\"\\n‚úÖ submission.csv: {len(df)} entries\")\n",
    "            print(f\"üìù Columns: {list(df.columns)}\")\n",
    "        except:\n",
    "            print(f\"\\n‚úÖ submission.csv exists\")\n",
    "    \n",
    "    # Check ZIP files\n",
    "    zip_files = list(Path(working_dir).glob('*.zip'))\n",
    "    if zip_files:\n",
    "        print(f\"\\nüì¶ ZIP files found:\")\n",
    "        for zf in zip_files:\n",
    "            size = os.path.getsize(zf) / (1024 * 1024)\n",
    "            print(f\"   ‚Ä¢ {zf.name}: {size:.2f} MB\")\n",
    "\n",
    "# Run verification\n",
    "verify_all_outputs()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ READY FOR SUBMISSION!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf886a33",
   "metadata": {
    "papermill": {
     "duration": 0.088939,
     "end_time": "2026-02-21T22:45:19.795579",
     "exception": false,
     "start_time": "2026-02-21T22:45:19.706640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 9: High Quality ZIP Creator (100% Quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6932c5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T22:45:19.969849Z",
     "iopub.status.busy": "2026-02-21T22:45:19.969575Z",
     "iopub.status.idle": "2026-02-21T22:47:40.888380Z",
     "shell.execute_reply": "2026-02-21T22:47:40.887401Z"
    },
    "papermill": {
     "duration": 141.008873,
     "end_time": "2026-02-21T22:47:40.890159",
     "exception": false,
     "start_time": "2026-02-21T22:45:19.881286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîß CREATING HIGH QUALITY ZIP (100%)\n",
      "============================================================\n",
      "üì∏ Total images: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:58<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved: 1000 images at 100% quality\n",
      "\n",
      "üì¶ Creating ZIP file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zipping: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:21<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ High Quality ZIP created: /kaggle/working/corrected_images_final.zip\n",
      "üì¶ Size: 2046.92 MB\n",
      "‚ö†Ô∏è File >500MB - Use Standard ZIP instead\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üîß HIGH QUALITY ZIP CREATOR - 100% QUALITY\n",
    "# =============================================================================\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîß CREATING HIGH QUALITY ZIP (100%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Paths\n",
    "input_folder = '/kaggle/working/corrected_images'\n",
    "output_folder = '/kaggle/working/corrected_images_fixed'\n",
    "output_zip = '/kaggle/working/corrected_images_final.zip'\n",
    "\n",
    "if not os.path.exists(input_folder):\n",
    "    print(f\"‚ùå Input folder not found: {input_folder}\")\n",
    "else:\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get images\n",
    "    image_files = list(Path(input_folder).glob('*.jpg'))\n",
    "    print(f\"üì∏ Total images: {len(image_files)}\")\n",
    "\n",
    "    # Save with MAXIMUM quality\n",
    "    successful = 0\n",
    "    for img_path in tqdm(image_files, desc=\"Processing images\"):\n",
    "        try:\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is not None:\n",
    "                output_path = os.path.join(output_folder, img_path.name)\n",
    "                cv2.imwrite(output_path, img, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "                successful += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n‚úÖ Saved: {successful} images at 100% quality\")\n",
    "\n",
    "    # Create ZIP\n",
    "    if successful > 0:\n",
    "        print(\"\\nüì¶ Creating ZIP file...\")\n",
    "        with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for img_path in tqdm(list(Path(output_folder).glob('*.jpg')), desc=\"Zipping\"):\n",
    "                zipf.write(img_path, arcname=img_path.name)\n",
    "\n",
    "        # Show result\n",
    "        size_mb = os.path.getsize(output_zip) / (1024 * 1024)\n",
    "        print(f\"\\n‚úÖ High Quality ZIP created: {output_zip}\")\n",
    "        print(f\"üì¶ Size: {size_mb:.2f} MB\")\n",
    "\n",
    "        if size_mb > 500:\n",
    "            print(\"‚ö†Ô∏è File >500MB - Use Standard ZIP instead\")\n",
    "        else:\n",
    "            print(\"‚úÖ File ready for upload!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b242e",
   "metadata": {
    "papermill": {
     "duration": 0.121458,
     "end_time": "2026-02-21T22:47:41.135440",
     "exception": false,
     "start_time": "2026-02-21T22:47:41.013982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 10: Standard ZIP Creator (95% Quality) - Under 500MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbfd8b0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T22:47:41.381027Z",
     "iopub.status.busy": "2026-02-21T22:47:41.380477Z",
     "iopub.status.idle": "2026-02-21T22:49:12.358459Z",
     "shell.execute_reply": "2026-02-21T22:49:12.357700Z"
    },
    "papermill": {
     "duration": 91.10382,
     "end_time": "2026-02-21T22:49:12.360017",
     "exception": false,
     "start_time": "2026-02-21T22:47:41.256197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üì¶ CREATING STANDARD ZIP (95%)\n",
      "============================================================\n",
      "üì∏ Total images: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compressing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:49<00:00, 20.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Creating ZIP file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zipping: 1000it [00:41, 24.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Standard ZIP created: /kaggle/working/corrected_images_ready.zip\n",
      "üì¶ Size: 957.01 MB\n",
      "‚ö†Ô∏è Still >500MB - Try 85% quality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üì¶ STANDARD ZIP CREATOR - 95% QUALITY (<500MB)\n",
    "# =============================================================================\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üì¶ CREATING STANDARD ZIP (95%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Paths\n",
    "input_folder = '/kaggle/working/corrected_images'\n",
    "temp_folder = '/kaggle/working/temp_compressed'\n",
    "output_zip = '/kaggle/working/corrected_images_ready.zip'\n",
    "\n",
    "if not os.path.exists(input_folder):\n",
    "    print(f\"‚ùå Input folder not found: {input_folder}\")\n",
    "else:\n",
    "    os.makedirs(temp_folder, exist_ok=True)\n",
    "\n",
    "    # Get images\n",
    "    image_files = list(Path(input_folder).glob('*.jpg'))\n",
    "    print(f\"üì∏ Total images: {len(image_files)}\")\n",
    "\n",
    "    # Compress with 95% quality\n",
    "    for img_path in tqdm(image_files, desc=\"Compressing\"):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        out_path = os.path.join(temp_folder, img_path.name)\n",
    "        cv2.imwrite(out_path, img, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
    "\n",
    "    # Create ZIP\n",
    "    print(\"\\nüì¶ Creating ZIP file...\")\n",
    "    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for img_path in tqdm(Path(temp_folder).glob('*.jpg'), desc=\"Zipping\"):\n",
    "            zipf.write(img_path, arcname=img_path.name)\n",
    "\n",
    "    # Show result\n",
    "    size_mb = os.path.getsize(output_zip) / (1024 * 1024)\n",
    "    print(f\"\\n‚úÖ Standard ZIP created: {output_zip}\")\n",
    "    print(f\"üì¶ Size: {size_mb:.2f} MB\")\n",
    "\n",
    "    if size_mb <= 500:\n",
    "        print(\"‚úÖ Ready for upload!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Still >500MB - Try 85% quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172ff2c",
   "metadata": {
    "papermill": {
     "duration": 0.146854,
     "end_time": "2026-02-21T22:49:12.732911",
     "exception": false,
     "start_time": "2026-02-21T22:49:12.586057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 11: Emergency Compressor (85% Quality) - Guaranteed <500MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d00846ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T22:49:13.024979Z",
     "iopub.status.busy": "2026-02-21T22:49:13.024681Z",
     "iopub.status.idle": "2026-02-21T22:50:16.335613Z",
     "shell.execute_reply": "2026-02-21T22:50:16.334913Z"
    },
    "papermill": {
     "duration": 63.617799,
     "end_time": "2026-02-21T22:50:16.496362",
     "exception": false,
     "start_time": "2026-02-21T22:49:12.878563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üóúÔ∏è EMERGENCY COMPRESSION - 85% QUALITY\n",
      "============================================================\n",
      "üì∏ Total images: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compressing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:45<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Emergency ZIP: 455.38 MB\n",
      "‚úÖ Guaranteed <500MB - Ready for upload!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üóúÔ∏è EMERGENCY COMPRESSOR - 85% QUALITY (GUARANTEED <500MB)\n",
    "# =============================================================================\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üóúÔ∏è EMERGENCY COMPRESSION - 85% QUALITY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Paths\n",
    "input_folder = '/kaggle/working/corrected_images'\n",
    "temp_folder = '/kaggle/working/temp_emergency'\n",
    "output_zip = '/kaggle/working/corrected_images_small.zip'\n",
    "\n",
    "if not os.path.exists(input_folder):\n",
    "    print(f\"‚ùå Input folder not found: {input_folder}\")\n",
    "else:\n",
    "    os.makedirs(temp_folder, exist_ok=True)\n",
    "\n",
    "    # Get images\n",
    "    image_files = list(Path(input_folder).glob('*.jpg'))\n",
    "    print(f\"üì∏ Total images: {len(image_files)}\")\n",
    "\n",
    "    # Compress with 85% quality\n",
    "    for img_path in tqdm(image_files, desc=\"Compressing\"):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        out_path = os.path.join(temp_folder, img_path.name)\n",
    "        cv2.imwrite(out_path, img, [cv2.IMWRITE_JPEG_QUALITY, 85])\n",
    "\n",
    "    # Create ZIP\n",
    "    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for img_path in Path(temp_folder).glob('*.jpg'):\n",
    "            zipf.write(img_path, arcname=img_path.name)\n",
    "\n",
    "    # Show result\n",
    "    size_mb = os.path.getsize(output_zip) / (1024 * 1024)\n",
    "    print(f\"\\n‚úÖ Emergency ZIP: {size_mb:.2f} MB\")\n",
    "    print(\"‚úÖ Guaranteed <500MB - Ready for upload!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8605697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T22:50:16.813432Z",
     "iopub.status.busy": "2026-02-21T22:50:16.813111Z",
     "iopub.status.idle": "2026-02-21T22:50:18.308676Z",
     "shell.execute_reply": "2026-02-21T22:50:18.307665Z"
    },
    "papermill": {
     "duration": 1.658006,
     "end_time": "2026-02-21T22:50:18.310161",
     "exception": false,
     "start_time": "2026-02-21T22:50:16.652155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üßπ CLEANING OLD FILES\n",
      "============================================================\n",
      "‚úÖ Deleted: /kaggle/working/corrected_images\n",
      "‚úÖ Deleted: /kaggle/working/corrected_images_fixed\n",
      "‚úÖ Deleted: /kaggle/working/temp_compressed\n",
      "‚úÖ Deleted: /kaggle/working/temp_emergency\n",
      "‚úÖ Deleted: /kaggle/working/corrected_images.zip\n",
      "‚úÖ Deleted: /kaggle/working/corrected_images_final.zip\n",
      "‚úÖ Deleted: /kaggle/working/corrected_images_ready.zip\n",
      "‚úÖ Deleted: /kaggle/working/corrected_images_small.zip\n",
      "\n",
      "‚úÖ Cleanup complete! Ready for fresh processing.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üßπ CLEANUP - DELETE OLD FILES\n",
    "# =============================================================================\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üßπ CLEANING OLD FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "folders_to_delete = [\n",
    "    '/kaggle/working/corrected_images',\n",
    "    '/kaggle/working/corrected_images_fixed',\n",
    "    '/kaggle/working/temp',\n",
    "    '/kaggle/working/temp_compressed',\n",
    "    '/kaggle/working/temp_emergency'\n",
    "]\n",
    "\n",
    "for folder in folders_to_delete:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "        print(f\"‚úÖ Deleted: {folder}\")\n",
    "\n",
    "files_to_delete = [\n",
    "    '/kaggle/working/corrected_images.zip',\n",
    "    '/kaggle/working/corrected_images_final.zip',\n",
    "    '/kaggle/working/corrected_images_ready.zip',\n",
    "    '/kaggle/working/corrected_images_small.zip'\n",
    "]\n",
    "\n",
    "for file in files_to_delete:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"‚úÖ Deleted: {file}\")\n",
    "\n",
    "print(\"\\n‚úÖ Cleanup complete! Ready for fresh processing.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 15769099,
     "sourceId": 130932,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31287,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1329.01181,
   "end_time": "2026-02-21T22:50:18.886345",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-21T22:28:09.874535",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
