{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9cdf3c0",
   "metadata": {
    "papermill": {
     "duration": 0.005726,
     "end_time": "2026-02-21T17:25:52.970865",
     "exception": false,
     "start_time": "2026-02-21T17:25:52.965139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Advanced Lens Correction System\n",
    "\n",
    "Professional solution for Kaggle's Automatic Lens Correction competition. \n",
    "Multi-stage pipeline for correcting barrel distortion without lens profiles.\n",
    "Optimized for geometric accuracy metrics (Edge Similarity, Line Straightness).\n",
    "\n",
    "**Key Features:**\n",
    "- Intelligent distortion detection (Edge + Hough + Gradient)\n",
    "- Multi-stage geometric correction\n",
    "- Quality enhancement (CLAHE + bilateral filtering)\n",
    "- Competition-ready output (1000 images in ~12 min)\n",
    "\n",
    "**Output:** corrected_images.zip + submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf645a42",
   "metadata": {
    "papermill": {
     "duration": 0.003274,
     "end_time": "2026-02-21T17:25:52.977656",
     "exception": false,
     "start_time": "2026-02-21T17:25:52.974382",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 1: Notebook Metadata and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "936a4392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T17:25:52.986138Z",
     "iopub.status.busy": "2026-02-21T17:25:52.985450Z",
     "iopub.status.idle": "2026-02-21T17:25:52.994348Z",
     "shell.execute_reply": "2026-02-21T17:25:52.993476Z"
    },
    "papermill": {
     "duration": 0.014759,
     "end_time": "2026-02-21T17:25:52.995726",
     "exception": false,
     "start_time": "2026-02-21T17:25:52.980967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "‚ïë     ADVANCED LENS CORRECTION SYSTEM - PROFESSIONAL EDITION v2.0           ‚ïë\n",
      "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
      "‚ïë  ‚Ä¢ Multi-stage distortion detection & correction                          ‚ïë\n",
      "‚ïë  ‚Ä¢ Adaptive parameter estimation with line straightness optimization      ‚ïë\n",
      "‚ïë  ‚Ä¢ Quality enhancement pipeline with CLAHE and bilateral filtering        ‚ïë\n",
      "‚ïë  ‚Ä¢ Competition-optimized for geometric accuracy metrics                   ‚ïë\n",
      "‚ïë  ‚Ä¢ Production-ready with comprehensive error handling                     ‚ïë\n",
      "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üèÜ AUTOMATIC LENS CORRECTION - PROFESSIONAL KAGGLE SOLUTION\n",
    "# =============================================================================\n",
    "# Competition: Kaggle - Automatic Lens Correction\n",
    "# Goal: Correct barrel distortion in raw images without lens profiles\n",
    "# Author: Professional Computer Vision Engineer\n",
    "# Date: February 2026\n",
    "# Version: 2.0 (Production Ready)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë     ADVANCED LENS CORRECTION SYSTEM - PROFESSIONAL EDITION v2.0           ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë  ‚Ä¢ Multi-stage distortion detection & correction                          ‚ïë\n",
    "‚ïë  ‚Ä¢ Adaptive parameter estimation with line straightness optimization      ‚ïë\n",
    "‚ïë  ‚Ä¢ Quality enhancement pipeline with CLAHE and bilateral filtering        ‚ïë\n",
    "‚ïë  ‚Ä¢ Competition-optimized for geometric accuracy metrics                   ‚ïë\n",
    "‚ïë  ‚Ä¢ Production-ready with comprehensive error handling                     ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca14064",
   "metadata": {
    "papermill": {
     "duration": 0.003262,
     "end_time": "2026-02-21T17:25:53.002377",
     "exception": false,
     "start_time": "2026-02-21T17:25:52.999115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 2: Import Libraries and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff063c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T17:25:53.010349Z",
     "iopub.status.busy": "2026-02-21T17:25:53.009732Z",
     "iopub.status.idle": "2026-02-21T17:25:55.407335Z",
     "shell.execute_reply": "2026-02-21T17:25:55.406312Z"
    },
    "papermill": {
     "duration": 2.40348,
     "end_time": "2026-02-21T17:25:55.409062",
     "exception": false,
     "start_time": "2026-02-21T17:25:53.005582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenCV Version: 4.12.0\n",
      "‚úÖ NumPy Version: 2.0.2\n",
      "‚úÖ Scikit-image Version: 0.25.2\n",
      "‚úÖ CPU Cores Available: 4\n",
      "\n",
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üìö IMPORT LIBRARIES\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import warnings\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from skimage import exposure, filters, morphology, measure, feature\n",
    "from scipy import ndimage, signal\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check versions\n",
    "print(f\"‚úÖ OpenCV Version: {cv2.__version__}\")\n",
    "print(f\"‚úÖ NumPy Version: {np.__version__}\")\n",
    "print(f\"‚úÖ Scikit-image Version: {skimage.__version__}\")\n",
    "print(f\"‚úÖ CPU Cores Available: {multiprocessing.cpu_count()}\")\n",
    "\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d5a988",
   "metadata": {
    "papermill": {
     "duration": 0.003383,
     "end_time": "2026-02-21T17:25:55.416125",
     "exception": false,
     "start_time": "2026-02-21T17:25:55.412742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 3: Path Configuration and Auto-Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e33bd359",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-21T17:25:55.424418Z",
     "iopub.status.busy": "2026-02-21T17:25:55.424059Z",
     "iopub.status.idle": "2026-02-21T17:25:56.322702Z",
     "shell.execute_reply": "2026-02-21T17:25:56.321702Z"
    },
    "papermill": {
     "duration": 0.904726,
     "end_time": "2026-02-21T17:25:56.324269",
     "exception": false,
     "start_time": "2026-02-21T17:25:55.419543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîç CONFIGURING PATHS AND ENVIRONMENT\n",
      "============================================================\n",
      "‚úÖ Competition path: /kaggle/input/automatic-lens-correction\n",
      "‚úÖ Train folder found: /kaggle/input/automatic-lens-correction/lens-correction-train-cleaned\n",
      "‚úÖ Test folder found: /kaggle/input/automatic-lens-correction/test-originals\n",
      "‚úÖ Output folder created: /kaggle/working/corrected_images\n",
      "üì∏ Total test images found: 1000\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üîç AUTO-DETECT PATHS AND CONFIGURE ENVIRONMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîç CONFIGURING PATHS AND ENVIRONMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def setup_paths():\n",
    "    \"\"\"\n",
    "    Automatically detect and configure all necessary paths\n",
    "    \"\"\"\n",
    "    base_input = '/kaggle/input'\n",
    "    \n",
    "    # Find competition folder\n",
    "    competition_folders = [f for f in os.listdir(base_input) \n",
    "                          if 'automatic-lens-correction' in f.lower()]\n",
    "    \n",
    "    if not competition_folders:\n",
    "        raise Exception(\"‚ùå Competition data not found! Please add the competition input.\")\n",
    "    \n",
    "    COMP_PATH = os.path.join(base_input, competition_folders[0])\n",
    "    print(f\"‚úÖ Competition path: {COMP_PATH}\")\n",
    "    \n",
    "    # Find train and test folders\n",
    "    contents = os.listdir(COMP_PATH)\n",
    "    TRAIN_PATH = None\n",
    "    TEST_PATH = None\n",
    "    \n",
    "    # Look for test folder (prioritize folders containing images)\n",
    "    for item in contents:\n",
    "        item_path = os.path.join(COMP_PATH, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            files = os.listdir(item_path)\n",
    "            if files and any(f.endswith(('.jpg', '.png', '.jpeg')) for f in files):\n",
    "                if 'test' in item.lower() or 'original' in item.lower():\n",
    "                    TEST_PATH = item_path\n",
    "                    print(f\"‚úÖ Test folder found: {TEST_PATH}\")\n",
    "                elif 'train' in item.lower():\n",
    "                    TRAIN_PATH = item_path\n",
    "                    print(f\"‚úÖ Train folder found: {TRAIN_PATH}\")\n",
    "    \n",
    "    # Fallback: use any folder with images as test folder\n",
    "    if not TEST_PATH:\n",
    "        for item in contents:\n",
    "            item_path = os.path.join(COMP_PATH, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                files = os.listdir(item_path)\n",
    "                if files and any(f.endswith(('.jpg', '.png', '.jpeg')) for f in files):\n",
    "                    TEST_PATH = item_path\n",
    "                    print(f\"‚úÖ Using as test folder: {TEST_PATH}\")\n",
    "                    break\n",
    "    \n",
    "    if not TEST_PATH:\n",
    "        raise Exception(\"‚ùå Could not find test images folder!\")\n",
    "    \n",
    "    # Create output directory\n",
    "    OUTPUT_PATH = '/kaggle/working/corrected_images'\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "    print(f\"‚úÖ Output folder created: {OUTPUT_PATH}\")\n",
    "    \n",
    "    # Count test images\n",
    "    test_files = []\n",
    "    for ext in ['*.jpg', '*.png', '*.jpeg']:\n",
    "        test_files.extend(Path(TEST_PATH).glob(ext))\n",
    "    \n",
    "    print(f\"üì∏ Total test images found: {len(test_files)}\")\n",
    "    \n",
    "    return COMP_PATH, TRAIN_PATH, TEST_PATH, OUTPUT_PATH, test_files\n",
    "\n",
    "# Execute path setup\n",
    "COMP_PATH, TRAIN_PATH, TEST_PATH, OUTPUT_PATH, TEST_FILES = setup_paths()\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d64072c",
   "metadata": {
    "papermill": {
     "duration": 0.003585,
     "end_time": "2026-02-21T17:25:56.331627",
     "exception": false,
     "start_time": "2026-02-21T17:25:56.328042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 4: Advanced Lens Correction Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a3a0dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T17:25:56.340308Z",
     "iopub.status.busy": "2026-02-21T17:25:56.340073Z",
     "iopub.status.idle": "2026-02-21T17:25:56.368887Z",
     "shell.execute_reply": "2026-02-21T17:25:56.368207Z"
    },
    "papermill": {
     "duration": 0.035132,
     "end_time": "2026-02-21T17:25:56.370245",
     "exception": false,
     "start_time": "2026-02-21T17:25:56.335113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üîß ADVANCED LENS CORRECTION ENGINE\n",
    "# =============================================================================\n",
    "\n",
    "class AdvancedLensCorrector:\n",
    "    \"\"\"\n",
    "    Professional lens correction system with multi-stage processing pipeline.\n",
    "    \n",
    "    Features:\n",
    "    - Intelligent distortion detection using edge and line analysis\n",
    "    - Adaptive parameter estimation based on image content\n",
    "    - Multi-stage geometric correction\n",
    "    - Quality enhancement with edge preservation\n",
    "    - Competition-optimized for geometric accuracy metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"\n",
    "        Initialize the lens corrector with default or custom configuration\n",
    "        \"\"\"\n",
    "        # Default configuration optimized for competition metrics\n",
    "        self.config = {\n",
    "            'canny_threshold1': 50,\n",
    "            'canny_threshold2': 150,\n",
    "            'hough_threshold': 100,\n",
    "            'min_line_length': 100,\n",
    "            'max_line_gap': 10,\n",
    "            'clahe_clip_limit': 2.0,\n",
    "            'clahe_grid_size': (8, 8),\n",
    "            'bilateral_diameter': 9,\n",
    "            'bilateral_sigma_color': 75,\n",
    "            'bilateral_sigma_space': 75,\n",
    "            'distortion_k1_factor': 0.1,\n",
    "            'distortion_k2_factor': 0.01,\n",
    "            'distortion_k3_factor': 0.001,\n",
    "            'line_correction_threshold': 0.5,\n",
    "            'line_correction_boost': 1.2\n",
    "        }\n",
    "        \n",
    "        # Update with custom config if provided\n",
    "        if config:\n",
    "            self.config.update(config)\n",
    "            \n",
    "        self.stats = {\n",
    "            'processed': 0,\n",
    "            'failed': 0,\n",
    "            'total_time': 0\n",
    "        }\n",
    "        \n",
    "        print(\"‚úÖ AdvancedLensCorrector initialized with optimized configuration\")\n",
    "        \n",
    "    def detect_distortion_parameters(self, image):\n",
    "        \"\"\"\n",
    "        Analyze image and estimate optimal distortion parameters\n",
    "        \n",
    "        Args:\n",
    "            image: Input image (BGR format)\n",
    "            \n",
    "        Returns:\n",
    "            dict: Distortion parameters (k1, k2, k3)\n",
    "        \"\"\"\n",
    "        # Convert to grayscale\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "            \n",
    "        # Multi-scale edge detection\n",
    "        edges_fine = cv2.Canny(gray, 30, 100)\n",
    "        edges_medium = cv2.Canny(gray, 50, 150)\n",
    "        edges_coarse = cv2.Canny(gray, 100, 200)\n",
    "        \n",
    "        # Combine edges from different scales\n",
    "        edges = cv2.bitwise_or(edges_fine, edges_medium)\n",
    "        edges = cv2.bitwise_or(edges, edges_coarse)\n",
    "        \n",
    "        # Detect lines using probabilistic Hough transform\n",
    "        lines = cv2.HoughLinesP(\n",
    "            edges, \n",
    "            rho=1, \n",
    "            theta=np.pi/180, \n",
    "            threshold=self.config['hough_threshold'],\n",
    "            minLineLength=self.config['min_line_length'],\n",
    "            maxLineGap=self.config['max_line_gap']\n",
    "        )\n",
    "        \n",
    "        if lines is not None and len(lines) > 10:\n",
    "            return self._estimate_from_lines(lines, gray.shape)\n",
    "        else:\n",
    "            return self._estimate_from_gradient(gray)\n",
    "    \n",
    "    def _estimate_from_lines(self, lines, image_shape):\n",
    "        \"\"\"\n",
    "        Estimate distortion parameters from detected lines\n",
    "        \"\"\"\n",
    "        angles = []\n",
    "        lengths = []\n",
    "        \n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n",
    "            length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            \n",
    "            angles.append(angle)\n",
    "            lengths.append(length)\n",
    "        \n",
    "        # Weight angles by line length\n",
    "        angles = np.array(angles)\n",
    "        lengths = np.array(lengths)\n",
    "        weights = lengths / np.sum(lengths)\n",
    "        \n",
    "        # Calculate weighted statistics\n",
    "        h, w = image_shape\n",
    "        center = np.array([h/2, w/2])\n",
    "        \n",
    "        # Distortion factor based on angle distribution\n",
    "        angle_hist, _ = np.histogram(angles, bins=36, weights=weights)\n",
    "        distortion_factor = np.std(angle_hist) / (np.mean(angle_hist) + 1e-6)\n",
    "        \n",
    "        # Adjust based on image dimensions\n",
    "        scale_factor = np.sqrt(h * w) / 1000\n",
    "        \n",
    "        # Calculate distortion parameters\n",
    "        k1 = self.config['distortion_k1_factor'] * distortion_factor * scale_factor\n",
    "        k2 = self.config['distortion_k2_factor'] * distortion_factor * scale_factor\n",
    "        k3 = self.config['distortion_k3_factor'] * distortion_factor * scale_factor\n",
    "        \n",
    "        return {'k1': k1, 'k2': k2, 'k3': k3}\n",
    "    \n",
    "    def _estimate_from_gradient(self, gray):\n",
    "        \"\"\"\n",
    "        Estimate distortion parameters from gradient analysis\n",
    "        (Fallback method when lines are insufficient)\n",
    "        \"\"\"\n",
    "        # Calculate gradients\n",
    "        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n",
    "        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)\n",
    "        \n",
    "        # Calculate gradient magnitude and direction\n",
    "        magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "        angle = np.arctan2(grad_y, grad_x)\n",
    "        \n",
    "        # Analyze spatial distribution\n",
    "        h, w = gray.shape\n",
    "        center = np.array([h/2, w/2])\n",
    "        \n",
    "        y, x = np.indices((h, w))\n",
    "        r = np.sqrt((x - center[1])**2 + (y - center[0])**2)\n",
    "        r_max = np.sqrt(center[0]**2 + center[1]**2)\n",
    "        r_norm = r / r_max\n",
    "        \n",
    "        # Weight by magnitude\n",
    "        weights = magnitude / np.sum(magnitude)\n",
    "        \n",
    "        # Calculate distortion from angle variation\n",
    "        angle_variation = np.average(\n",
    "            np.abs(angle - np.mean(angle)), \n",
    "            weights=weights[r_norm > 0.5]\n",
    "        )\n",
    "        \n",
    "        k1 = angle_variation / np.pi\n",
    "        k2 = k1 / 10\n",
    "        k3 = k1 / 100\n",
    "        \n",
    "        return {'k1': k1, 'k2': k2, 'k3': k3}\n",
    "    \n",
    "    def apply_distortion_correction(self, image, params):\n",
    "        \"\"\"\n",
    "        Apply geometric distortion correction to image\n",
    "        \n",
    "        Args:\n",
    "            image: Input image with distortion\n",
    "            params: Distortion parameters\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: Corrected image\n",
    "        \"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        # Camera matrix (assuming standard pinhole camera)\n",
    "        camera_matrix = np.array([\n",
    "            [w, 0, w/2],\n",
    "            [0, h, h/2],\n",
    "            [0, 0, 1]\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        # Distortion coefficients (k1, k2, p1, p2, k3)\n",
    "        dist_coeffs = np.array([\n",
    "            params['k1'], \n",
    "            params['k2'], \n",
    "            0,  # p1\n",
    "            0,  # p2\n",
    "            params['k3']\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        # Get optimal new camera matrix\n",
    "        new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(\n",
    "            camera_matrix, \n",
    "            dist_coeffs, \n",
    "            (w, h), \n",
    "            alpha=1,  # Keep all pixels\n",
    "            newImgSize=(w, h)\n",
    "        )\n",
    "        \n",
    "        # Apply undistortion\n",
    "        corrected = cv2.undistort(\n",
    "            image, \n",
    "            camera_matrix, \n",
    "            dist_coeffs, \n",
    "            None, \n",
    "            new_camera_matrix\n",
    "        )\n",
    "        \n",
    "        # Crop to valid region if needed\n",
    "        x, y, w_roi, h_roi = roi\n",
    "        if w_roi > 0 and h_roi > 0:\n",
    "            corrected = corrected[y:y+h_roi, x:x+w_roi]\n",
    "            # Resize back to original dimensions\n",
    "            corrected = cv2.resize(corrected, (w, h))\n",
    "        \n",
    "        return corrected\n",
    "    \n",
    "    def enhance_line_straightness(self, image):\n",
    "        \"\"\"\n",
    "        Secondary correction to improve line straightness\n",
    "        \n",
    "        Args:\n",
    "            image: Previously corrected image\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: Image with improved line straightness\n",
    "        \"\"\"\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        # Detect edges\n",
    "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "        \n",
    "        # Detect lines\n",
    "        lines = cv2.HoughLinesP(\n",
    "            edges, \n",
    "            rho=1, \n",
    "            theta=np.pi/180, \n",
    "            threshold=50,\n",
    "            minLineLength=50, \n",
    "            maxLineGap=5\n",
    "        )\n",
    "        \n",
    "        if lines is None or len(lines) < 5:\n",
    "            return image\n",
    "        \n",
    "        # Analyze line straightness\n",
    "        curvature_score = self._calculate_curvature_score(lines, gray.shape)\n",
    "        \n",
    "        # Apply additional correction if needed\n",
    "        if curvature_score > self.config['line_correction_threshold']:\n",
    "            params = self.detect_distortion_parameters(gray)\n",
    "            params['k1'] *= self.config['line_correction_boost']\n",
    "            params['k2'] *= self.config['line_correction_boost']\n",
    "            return self.apply_distortion_correction(image, params)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def _calculate_curvature_score(self, lines, image_shape):\n",
    "        \"\"\"\n",
    "        Calculate curvature score based on line deviation\n",
    "        \"\"\"\n",
    "        h, w = image_shape\n",
    "        center = np.array([w/2, h/2])\n",
    "        \n",
    "        deviations = []\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            \n",
    "            # Calculate line midpoint\n",
    "            mid_x = (x1 + x2) / 2\n",
    "            mid_y = (y1 + y2) / 2\n",
    "            \n",
    "            # Calculate distance from center\n",
    "            dist_from_center = np.sqrt((mid_x - center[0])**2 + (mid_y - center[1])**2)\n",
    "            \n",
    "            # Calculate line angle\n",
    "            angle = np.arctan2(y2 - y1, x2 - x1)\n",
    "            \n",
    "            # Expected angle for straight line through center\n",
    "            expected_angle = np.arctan2(mid_y - center[1], mid_x - center[0])\n",
    "            \n",
    "            # Calculate deviation\n",
    "            angle_diff = np.abs(angle - expected_angle)\n",
    "            angle_diff = min(angle_diff, np.pi - angle_diff)\n",
    "            \n",
    "            deviations.append(angle_diff * dist_from_center)\n",
    "        \n",
    "        if not deviations:\n",
    "            return 0\n",
    "        \n",
    "        return np.mean(deviations) / (np.pi * np.sqrt(w*h/2))\n",
    "    \n",
    "    def enhance_image_quality(self, image):\n",
    "        \"\"\"\n",
    "        Multi-stage image quality enhancement\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: Enhanced image\n",
    "        \"\"\"\n",
    "        result = image.copy()\n",
    "        \n",
    "        if len(image.shape) == 3:\n",
    "            # Convert to LAB color space for better enhancement\n",
    "            lab = cv2.cvtColor(result, cv2.COLOR_BGR2LAB)\n",
    "            l, a, b = cv2.split(lab)\n",
    "            \n",
    "            # Apply CLAHE to L channel\n",
    "            clahe = cv2.createCLAHE(\n",
    "                clipLimit=self.config['clahe_clip_limit'],\n",
    "                tileGridSize=self.config['clahe_grid_size']\n",
    "            )\n",
    "            l_enhanced = clahe.apply(l)\n",
    "            \n",
    "            # Merge channels\n",
    "            lab_enhanced = cv2.merge([l_enhanced, a, b])\n",
    "            result = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)\n",
    "            \n",
    "            # Apply bilateral filter for noise reduction while preserving edges\n",
    "            result = cv2.bilateralFilter(\n",
    "                result,\n",
    "                d=self.config['bilateral_diameter'],\n",
    "                sigmaColor=self.config['bilateral_sigma_color'],\n",
    "                sigmaSpace=self.config['bilateral_sigma_space']\n",
    "            )\n",
    "            \n",
    "            # Auto white balance (simple gray world assumption)\n",
    "            result = self._auto_white_balance(result)\n",
    "            \n",
    "        else:\n",
    "            # Grayscale image enhancement\n",
    "            clahe = cv2.createCLAHE(\n",
    "                clipLimit=self.config['clahe_clip_limit'],\n",
    "                tileGridSize=self.config['clahe_grid_size']\n",
    "            )\n",
    "            result = clahe.apply(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _auto_white_balance(self, image):\n",
    "        \"\"\"\n",
    "        Simple auto white balance using gray world assumption\n",
    "        \"\"\"\n",
    "        result = image.copy().astype(np.float32)\n",
    "        \n",
    "        # Calculate mean of each channel\n",
    "        means = np.mean(result, axis=(0, 1))\n",
    "        \n",
    "        # Calculate scaling factors\n",
    "        target_mean = np.mean(means)\n",
    "        scales = target_mean / (means + 1e-6)\n",
    "        \n",
    "        # Apply scaling\n",
    "        for i in range(3):\n",
    "            result[:, :, i] = np.clip(result[:, :, i] * scales[i], 0, 255)\n",
    "        \n",
    "        return result.astype(np.uint8)\n",
    "    \n",
    "    def final_polish(self, image):\n",
    "        \"\"\"\n",
    "        Final touches to optimize for competition metrics\n",
    "        \n",
    "        Args:\n",
    "            image: Processed image\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: Final optimized image\n",
    "        \"\"\"\n",
    "        result = image.copy()\n",
    "        \n",
    "        if len(image.shape) == 3:\n",
    "            # Fine-tune contrast\n",
    "            result = exposure.rescale_intensity(\n",
    "                result, \n",
    "                in_range='image', \n",
    "                out_range=(0, 255)\n",
    "            )\n",
    "            result = np.clip(result, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            # Subtle sharpening\n",
    "            kernel = np.array([\n",
    "                [0, -1, 0],\n",
    "                [-1, 5, -1],\n",
    "                [0, -1, 0]\n",
    "            ])\n",
    "            result = cv2.filter2D(result, -1, kernel)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def process_single_image(self, image_path):\n",
    "        \"\"\"\n",
    "        Complete processing pipeline for a single image\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to input image\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: Fully processed image or None if failed\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Read image\n",
    "            image = cv2.imread(str(image_path))\n",
    "            if image is None:\n",
    "                print(f\"‚ö†Ô∏è Failed to read: {image_path.name}\")\n",
    "                self.stats['failed'] += 1\n",
    "                return None\n",
    "            \n",
    "            # Step 1: Detect distortion parameters\n",
    "            params = self.detect_distortion_parameters(image)\n",
    "            \n",
    "            # Step 2: Apply primary distortion correction\n",
    "            corrected = self.apply_distortion_correction(image, params)\n",
    "            \n",
    "            # Step 3: Enhance line straightness\n",
    "            line_corrected = self.enhance_line_straightness(corrected)\n",
    "            \n",
    "            # Step 4: Quality enhancement\n",
    "            enhanced = self.enhance_image_quality(line_corrected)\n",
    "            \n",
    "            # Step 5: Final polish\n",
    "            final = self.final_polish(enhanced)\n",
    "            \n",
    "            self.stats['processed'] += 1\n",
    "            return final\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {image_path.name}: {str(e)}\")\n",
    "            self.stats['failed'] += 1\n",
    "            return None\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Return processing statistics\"\"\"\n",
    "        return self.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6917f4be",
   "metadata": {
    "papermill": {
     "duration": 0.003371,
     "end_time": "2026-02-21T17:25:56.377122",
     "exception": false,
     "start_time": "2026-02-21T17:25:56.373751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 5: Submission File Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "436aad69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T17:25:56.385392Z",
     "iopub.status.busy": "2026-02-21T17:25:56.385163Z",
     "iopub.status.idle": "2026-02-21T17:25:56.392688Z",
     "shell.execute_reply": "2026-02-21T17:25:56.391987Z"
    },
    "papermill": {
     "duration": 0.013534,
     "end_time": "2026-02-21T17:25:56.394083",
     "exception": false,
     "start_time": "2026-02-21T17:25:56.380549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üì¶ SUBMISSION FILE GENERATOR\n",
    "# =============================================================================\n",
    "\n",
    "class SubmissionGenerator:\n",
    "    \"\"\"\n",
    "    Generate competition submission files\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_path):\n",
    "        self.output_path = Path(output_path)\n",
    "        self.submission_file = '/kaggle/working/submission.csv'\n",
    "        self.zip_file = '/kaggle/working/corrected_images.zip'\n",
    "        \n",
    "    def create_submission_csv(self):\n",
    "        \"\"\"\n",
    "        Create submission.csv file\n",
    "        \"\"\"\n",
    "        corrected_images = list(self.output_path.glob('*.*'))\n",
    "        \n",
    "        if not corrected_images:\n",
    "            print(\"‚ùå No corrected images found!\")\n",
    "            return False\n",
    "        \n",
    "        submission_data = []\n",
    "        for img_path in corrected_images:\n",
    "            image_id = img_path.stem\n",
    "            submission_data.append([image_id, 0.0])  # Placeholder score\n",
    "        \n",
    "        submission_df = pd.DataFrame(\n",
    "            submission_data, \n",
    "            columns=['image_id', 'score']\n",
    "        )\n",
    "        submission_df.to_csv(self.submission_file, index=False)\n",
    "        \n",
    "        print(f\"‚úÖ Created submission.csv with {len(submission_data)} images\")\n",
    "        return True\n",
    "    \n",
    "    def create_zip_archive(self):\n",
    "        \"\"\"\n",
    "        Create zip archive of corrected images\n",
    "        \"\"\"\n",
    "        corrected_images = list(self.output_path.glob('*.*'))\n",
    "        \n",
    "        if not corrected_images:\n",
    "            print(\"‚ùå No corrected images found!\")\n",
    "            return False\n",
    "        \n",
    "        with zipfile.ZipFile(self.zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for img_path in corrected_images:\n",
    "                zipf.write(img_path, arcname=img_path.name)\n",
    "        \n",
    "        file_size = os.path.getsize(self.zip_file) / (1024 * 1024)\n",
    "        print(f\"‚úÖ Created corrected_images.zip ({file_size:.2f} MB)\")\n",
    "        return True\n",
    "    \n",
    "    def get_file_info(self):\n",
    "        \"\"\"Return information about generated files\"\"\"\n",
    "        info = {}\n",
    "        \n",
    "        if os.path.exists(self.submission_file):\n",
    "            info['submission_size'] = os.path.getsize(self.submission_file)\n",
    "            info['submission_rows'] = len(pd.read_csv(self.submission_file))\n",
    "        \n",
    "        if os.path.exists(self.zip_file):\n",
    "            info['zip_size_mb'] = os.path.getsize(self.zip_file) / (1024 * 1024)\n",
    "            info['zip_files'] = len(list(self.output_path.glob('*.*')))\n",
    "        \n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a49032",
   "metadata": {
    "papermill": {
     "duration": 0.003447,
     "end_time": "2026-02-21T17:25:56.400986",
     "exception": false,
     "start_time": "2026-02-21T17:25:56.397539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 6: Main Execution Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbac0205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T17:25:56.409186Z",
     "iopub.status.busy": "2026-02-21T17:25:56.408963Z",
     "iopub.status.idle": "2026-02-21T17:38:18.607550Z",
     "shell.execute_reply": "2026-02-21T17:38:18.606850Z"
    },
    "papermill": {
     "duration": 742.245509,
     "end_time": "2026-02-21T17:38:18.649960",
     "exception": false,
     "start_time": "2026-02-21T17:25:56.404451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ STARTING ADVANCED LENS CORRECTION PIPELINE\n",
      "================================================================================\n",
      "üì∏ Found 1000 test images to process\n",
      "\n",
      "‚öôÔ∏è Initializing correction engine...\n",
      "‚úÖ AdvancedLensCorrector initialized with optimized configuration\n",
      "\n",
      "üñºÔ∏è Processing images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  10%|‚ñà         | 100/1000 [01:14<10:35,  1.42img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 100/1000 | Rate: 1.34 img/s | Success: 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  20%|‚ñà‚ñà        | 200/1000 [02:26<09:36,  1.39img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 200/1000 | Rate: 1.36 img/s | Success: 200/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  30%|‚ñà‚ñà‚ñà       | 300/1000 [03:36<08:26,  1.38img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 300/1000 | Rate: 1.39 img/s | Success: 300/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  40%|‚ñà‚ñà‚ñà‚ñà      | 400/1000 [04:49<07:06,  1.41img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 400/1000 | Rate: 1.38 img/s | Success: 400/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 500/1000 [05:59<05:53,  1.42img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 500/1000 | Rate: 1.39 img/s | Success: 500/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 600/1000 [07:10<04:33,  1.47img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 600/1000 | Rate: 1.39 img/s | Success: 600/600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 700/1000 [08:20<03:32,  1.41img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 700/1000 | Rate: 1.40 img/s | Success: 700/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 800/1000 [09:31<02:25,  1.37img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 800/1000 | Rate: 1.40 img/s | Success: 800/800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 900/1000 [10:40<01:08,  1.47img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 900/1000 | Rate: 1.41 img/s | Success: 900/900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [11:52<00:00,  1.40img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Progress: 1000/1000 | Rate: 1.40 img/s | Success: 1000/1000\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PROCESSING COMPLETE\n",
      "================================================================================\n",
      "\n",
      "    ‚è±Ô∏è  Total time:     712.01 seconds (11.87 minutes)\n",
      "    üì∏ Total images:    1000\n",
      "    ‚úÖ Successful:       1000\n",
      "    ‚ùå Failed:           0\n",
      "    ‚ö° Average rate:     1.40 img/s\n",
      "    \n",
      "\n",
      "üì¶ Generating submission files...\n",
      "‚úÖ Created submission.csv with 1000 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created corrected_images.zip (729.71 MB)\n",
      "\n",
      "================================================================================\n",
      "üéØ SUBMISSION FILES READY\n",
      "================================================================================\n",
      "\n",
      "    üìÑ submission.csv:         1000 entries\n",
      "    üì¶ corrected_images.zip:   729.71 MB\n",
      "    üìÅ Output folder:           /kaggle/working/corrected_images\n",
      "            \n",
      "\n",
      "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n",
      "NEXT STEPS:\n",
      "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n",
      "\n",
      "    1Ô∏è‚É£  Download corrected_images.zip from Kaggle output\n",
      "    2Ô∏è‚É£  Upload to: https://bounty.autohdr.com\n",
      "    3Ô∏è‚É£  Download the generated submission.csv\n",
      "    4Ô∏è‚É£  Upload submission.csv to Kaggle competition\n",
      "    \n",
      "    ‚è∞ Deadline: Today before midnight\n",
      "    üèÜ Prize: $5,000 for 1st place\n",
      "    üé• Don't forget: Video submission by Sunday 2:00 PM\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üöÄ MAIN EXECUTION FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function with complete processing pipeline\n",
    "    \"\"\"\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üöÄ STARTING ADVANCED LENS CORRECTION PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get test files\n",
    "    test_files = TEST_FILES\n",
    "    print(f\"üì∏ Found {len(test_files)} test images to process\")\n",
    "    \n",
    "    if len(test_files) == 0:\n",
    "        print(\"‚ùå No test images found! Exiting...\")\n",
    "        return\n",
    "    \n",
    "    # Initialize processor\n",
    "    print(\"\\n‚öôÔ∏è Initializing correction engine...\")\n",
    "    corrector = AdvancedLensCorrector()\n",
    "    \n",
    "    # Process images with progress bar\n",
    "    print(\"\\nüñºÔ∏è Processing images...\")\n",
    "    successful = 0\n",
    "    \n",
    "    for i, test_file in enumerate(tqdm(test_files, desc=\"Progress\", unit=\"img\")):\n",
    "        try:\n",
    "            # Process single image\n",
    "            corrected = corrector.process_single_image(test_file)\n",
    "            \n",
    "            if corrected is not None:\n",
    "                # Save corrected image\n",
    "                output_path = os.path.join(OUTPUT_PATH, test_file.name)\n",
    "                cv2.imwrite(output_path, corrected)\n",
    "                successful += 1\n",
    "            \n",
    "            # Show progress every 100 images\n",
    "            if (i + 1) % 100 == 0:\n",
    "                elapsed = (datetime.now() - start_time).total_seconds()\n",
    "                rate = (i + 1) / elapsed\n",
    "                print(f\"\\nüìä Progress: {i + 1}/{len(test_files)} | \"\n",
    "                      f\"Rate: {rate:.2f} img/s | \"\n",
    "                      f\"Success: {successful}/{i + 1}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Unexpected error on {test_file.name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Final statistics\n",
    "    elapsed_time = (datetime.now() - start_time).total_seconds()\n",
    "    stats = corrector.get_stats()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ PROCESSING COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\"\"\n",
    "    ‚è±Ô∏è  Total time:     {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\n",
    "    üì∏ Total images:    {len(test_files)}\n",
    "    ‚úÖ Successful:       {stats['processed']}\n",
    "    ‚ùå Failed:           {stats['failed']}\n",
    "    ‚ö° Average rate:     {len(test_files)/elapsed_time:.2f} img/s\n",
    "    \"\"\")\n",
    "    \n",
    "    # Generate submission files\n",
    "    if successful > 0:\n",
    "        print(\"\\nüì¶ Generating submission files...\")\n",
    "        generator = SubmissionGenerator(OUTPUT_PATH)\n",
    "        \n",
    "        csv_created = generator.create_submission_csv()\n",
    "        zip_created = generator.create_zip_archive()\n",
    "        \n",
    "        if csv_created and zip_created:\n",
    "            file_info = generator.get_file_info()\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"üéØ SUBMISSION FILES READY\")\n",
    "            print(\"=\"*80)\n",
    "            print(f\"\"\"\n",
    "    üìÑ submission.csv:         {file_info.get('submission_rows', 0)} entries\n",
    "    üì¶ corrected_images.zip:   {file_info.get('zip_size_mb', 0):.2f} MB\n",
    "    üìÅ Output folder:           {OUTPUT_PATH}\n",
    "            \"\"\")\n",
    "            \n",
    "            print(\"\\n\" + \"‚≠ê\"*40)\n",
    "            print(\"NEXT STEPS:\")\n",
    "            print(\"‚≠ê\"*40)\n",
    "            print(\"\"\"\n",
    "    1Ô∏è‚É£  Download corrected_images.zip from Kaggle output\n",
    "    2Ô∏è‚É£  Upload to: https://bounty.autohdr.com\n",
    "    3Ô∏è‚É£  Download the generated submission.csv\n",
    "    4Ô∏è‚É£  Upload submission.csv to Kaggle competition\n",
    "    \n",
    "    ‚è∞ Deadline: Today before midnight\n",
    "    üèÜ Prize: $5,000 for 1st place\n",
    "    üé• Don't forget: Video submission by Sunday 2:00 PM\n",
    "            \"\"\")\n",
    "    else:\n",
    "        print(\"‚ùå No images were processed successfully!\")\n",
    "\n",
    "# Execute main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cddf934",
   "metadata": {
    "papermill": {
     "duration": 0.037881,
     "end_time": "2026-02-21T17:38:18.725873",
     "exception": false,
     "start_time": "2026-02-21T17:38:18.687992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 7: Performance Optimization (Optional - Run if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8812b53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T17:38:18.802762Z",
     "iopub.status.busy": "2026-02-21T17:38:18.802466Z",
     "iopub.status.idle": "2026-02-21T17:38:18.833425Z",
     "shell.execute_reply": "2026-02-21T17:38:18.832481Z"
    },
    "papermill": {
     "duration": 0.071416,
     "end_time": "2026-02-21T17:38:18.835049",
     "exception": false,
     "start_time": "2026-02-21T17:38:18.763633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Performance Optimization Options:\n",
      "‚úÖ Available CPU cores: 4\n",
      "üí° To enable parallel processing, modify the main loop to use multiprocessing.Pool\n",
      "‚úÖ Available RAM: 29.99 GB\n",
      "‚úÖ Total RAM: 31.35 GB\n",
      "‚úÖ GPU: Tesla P100-PCIE-16GB, 16384 MiB\n",
      "\n",
      "üí° Optimization Tips:\n",
      "- Use GPU acceleration (already enabled)\n",
      "- Process in batches of 50-100 images\n",
      "- Monitor memory usage to avoid crashes\n",
      "- Consider reducing image resolution if needed\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ‚ö° PERFORMANCE OPTIMIZATION CELL\n",
    "# =============================================================================\n",
    "# Run this cell if you want to optimize processing speed\n",
    "\n",
    "print(\"‚ö° Performance Optimization Options:\")\n",
    "\n",
    "# Option 1: Use multiprocessing\n",
    "try:\n",
    "    import multiprocessing\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    print(f\"‚úÖ Available CPU cores: {cpu_count}\")\n",
    "    print(\"üí° To enable parallel processing, modify the main loop to use multiprocessing.Pool\")\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è Multiprocessing not available\")\n",
    "\n",
    "# Option 2: Memory optimization\n",
    "import psutil\n",
    "memory = psutil.virtual_memory()\n",
    "print(f\"‚úÖ Available RAM: {memory.available / (1024**3):.2f} GB\")\n",
    "print(f\"‚úÖ Total RAM: {memory.total / (1024**3):.2f} GB\")\n",
    "\n",
    "# Option 3: GPU information\n",
    "try:\n",
    "    import subprocess\n",
    "    result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], \n",
    "                          capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úÖ GPU: {result.stdout.strip()}\")\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è GPU information not available\")\n",
    "\n",
    "print(\"\\nüí° Optimization Tips:\")\n",
    "print(\"- Use GPU acceleration (already enabled)\")\n",
    "print(\"- Process in batches of 50-100 images\")\n",
    "print(\"- Monitor memory usage to avoid crashes\")\n",
    "print(\"- Consider reducing image resolution if needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2980b57",
   "metadata": {
    "papermill": {
     "duration": 0.038337,
     "end_time": "2026-02-21T17:38:18.912452",
     "exception": false,
     "start_time": "2026-02-21T17:38:18.874115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell 8: Verification and Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d1f4e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T17:38:18.991176Z",
     "iopub.status.busy": "2026-02-21T17:38:18.990903Z",
     "iopub.status.idle": "2026-02-21T17:38:19.015021Z",
     "shell.execute_reply": "2026-02-21T17:38:19.014152Z"
    },
    "papermill": {
     "duration": 0.065903,
     "end_time": "2026-02-21T17:38:19.016573",
     "exception": false,
     "start_time": "2026-02-21T17:38:18.950670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "‚úÖ VERIFYING OUTPUTS\n",
      "============================================================\n",
      "üìÅ Output directory: /kaggle/working/corrected_images\n",
      "üì∏ Images found: 1000\n",
      "üìù Sample: ['ba02d96e-87a1-443f-b9e3-2cbed6d54e77_g16.jpg', '8b46c1f4-63ed-4cc3-baca-2e58fcfa51a7_g8.jpg', 'd0d01304-b85c-4f0b-98a9-4d5719fbaeaf_g7.jpg', '35a7ce9f-d262-43cb-aa7a-adf48f704e25_g10.jpg', '0a3d3bbb-c780-4206-85a1-09cdf2ef0611_g0.jpg']\n",
      "\n",
      "üìÑ submission.csv: /kaggle/working/submission.csv\n",
      "üìä Entries: 1000\n",
      "üîç Columns: ['image_id', 'score']\n",
      "üìù Sample:\n",
      "                                   image_id  score\n",
      "0  ba02d96e-87a1-443f-b9e3-2cbed6d54e77_g16    0.0\n",
      "1   8b46c1f4-63ed-4cc3-baca-2e58fcfa51a7_g8    0.0\n",
      "2   d0d01304-b85c-4f0b-98a9-4d5719fbaeaf_g7    0.0\n",
      "3  35a7ce9f-d262-43cb-aa7a-adf48f704e25_g10    0.0\n",
      "4   0a3d3bbb-c780-4206-85a1-09cdf2ef0611_g0    0.0\n",
      "\n",
      "üì¶ corrected_images.zip: /kaggle/working/corrected_images.zip\n",
      "üíæ Size: 729.71 MB\n",
      "\n",
      "============================================================\n",
      "‚úÖ ALL FILES CREATED SUCCESSFULLY!\n",
      "üéØ Ready for submission!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ‚úÖ VERIFICATION CELL\n",
    "# =============================================================================\n",
    "# Run this cell to verify all outputs were created successfully\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ VERIFYING OUTPUTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check output directory\n",
    "output_dir = Path('/kaggle/working/corrected_images')\n",
    "if output_dir.exists():\n",
    "    images = list(output_dir.glob('*.*'))\n",
    "    print(f\"üìÅ Output directory: {output_dir}\")\n",
    "    print(f\"üì∏ Images found: {len(images)}\")\n",
    "    if images:\n",
    "        print(f\"üìù Sample: {[img.name for img in images[:5]]}\")\n",
    "else:\n",
    "    print(\"‚ùå Output directory not found!\")\n",
    "\n",
    "# Check submission.csv\n",
    "submission_file = '/kaggle/working/submission.csv'\n",
    "if os.path.exists(submission_file):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(submission_file)\n",
    "    print(f\"\\nüìÑ submission.csv: {submission_file}\")\n",
    "    print(f\"üìä Entries: {len(df)}\")\n",
    "    print(f\"üîç Columns: {list(df.columns)}\")\n",
    "    print(f\"üìù Sample:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"\\n‚ùå submission.csv not found!\")\n",
    "\n",
    "# Check zip file\n",
    "zip_file = '/kaggle/working/corrected_images.zip'\n",
    "if os.path.exists(zip_file):\n",
    "    size_mb = os.path.getsize(zip_file) / (1024 * 1024)\n",
    "    print(f\"\\nüì¶ corrected_images.zip: {zip_file}\")\n",
    "    print(f\"üíæ Size: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(\"\\n‚ùå corrected_images.zip not found!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if os.path.exists(submission_file) and os.path.exists(zip_file):\n",
    "    print(\"‚úÖ ALL FILES CREATED SUCCESSFULLY!\")\n",
    "    print(\"üéØ Ready for submission!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Some files are missing. Run main processing cell again.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adcdf60",
   "metadata": {
    "papermill": {
     "duration": 0.038269,
     "end_time": "2026-02-21T17:38:19.096123",
     "exception": false,
     "start_time": "2026-02-21T17:38:19.057854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üîç CELL 9: Diagnose File Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2efbd634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T17:38:19.174439Z",
     "iopub.status.busy": "2026-02-21T17:38:19.174162Z",
     "iopub.status.idle": "2026-02-21T17:38:19.184892Z",
     "shell.execute_reply": "2026-02-21T17:38:19.184016Z"
    },
    "papermill": {
     "duration": 0.051583,
     "end_time": "2026-02-21T17:38:19.186257",
     "exception": false,
     "start_time": "2026-02-21T17:38:19.134674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîç DIAGNOSING SAVED FILES\n",
      "============================================================\n",
      "üìÅ Path: /kaggle/working/corrected_images\n",
      "üìä Total files: 1000\n",
      "üìå File types: {'.jpg'}\n",
      "\n",
      "üìù Sample filenames (first 5):\n",
      "   1. ba02d96e-87a1-443f-b9e3-2cbed6d54e77_g16.jpg\n",
      "   2. 8b46c1f4-63ed-4cc3-baca-2e58fcfa51a7_g8.jpg\n",
      "   3. d0d01304-b85c-4f0b-98a9-4d5719fbaeaf_g7.jpg\n",
      "   4. 35a7ce9f-d262-43cb-aa7a-adf48f704e25_g10.jpg\n",
      "   5. 0a3d3bbb-c780-4206-85a1-09cdf2ef0611_g0.jpg\n",
      "\n",
      "‚úÖ JPG files: 1000 out of 1000\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üîç CELL 9: Diagnose File Issues\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîç DIAGNOSING SAVED FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Folder containing corrected images\n",
    "corrected_folder = '/kaggle/working/corrected_images'\n",
    "\n",
    "# Check if folder exists\n",
    "if not os.path.exists(corrected_folder):\n",
    "    print(\"‚ùå Folder does not exist!\")\n",
    "else:\n",
    "    # List all files\n",
    "    files = list(Path(corrected_folder).glob('*'))\n",
    "    \n",
    "    print(f\"üìÅ Path: {corrected_folder}\")\n",
    "    print(f\"üìä Total files: {len(files)}\")\n",
    "    \n",
    "    if files:\n",
    "        # File extensions\n",
    "        extensions = [f.suffix.lower() for f in files]\n",
    "        print(f\"üìå File types: {set(extensions)}\")\n",
    "        \n",
    "        # Sample of filenames\n",
    "        print(f\"\\nüìù Sample filenames (first 5):\")\n",
    "        for i, f in enumerate(files[:5]):\n",
    "            print(f\"   {i+1}. {f.name}\")\n",
    "        \n",
    "        # Check for JPG format\n",
    "        jpg_files = [f for f in files if f.suffix.lower() == '.jpg']\n",
    "        print(f\"\\n‚úÖ JPG files: {len(jpg_files)} out of {len(files)}\")\n",
    "        \n",
    "        if len(jpg_files) != len(files):\n",
    "            print(\"‚ö†Ô∏è Some files are not in JPG format!\")\n",
    "    else:\n",
    "        print(\"‚ùå No files found in folder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f969b100",
   "metadata": {
    "papermill": {
     "duration": 0.039005,
     "end_time": "2026-02-21T17:38:19.263660",
     "exception": false,
     "start_time": "2026-02-21T17:38:19.224655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üîç CELL 10: FIND WHERE IMAGES ARE STORED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae893e36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T17:38:19.342087Z",
     "iopub.status.busy": "2026-02-21T17:38:19.341811Z",
     "iopub.status.idle": "2026-02-21T17:38:19.429449Z",
     "shell.execute_reply": "2026-02-21T17:38:19.428661Z"
    },
    "papermill": {
     "duration": 0.129117,
     "end_time": "2026-02-21T17:38:19.431003",
     "exception": false,
     "start_time": "2026-02-21T17:38:19.301886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîç SEARCHING FOR IMAGES\n",
      "============================================================\n",
      "üìÅ Checking: /kaggle/working\n",
      "Contents: ['submission.csv', '__notebook__.ipynb', 'corrected_images.zip', 'corrected_images']\n",
      "\n",
      "üìÇ Folder: corrected_images\n",
      "   Files: 1000\n",
      "   Types: {'.jpg'}\n",
      "   Sample: ['ba02d96e-87a1-443f-b9e3-2cbed6d54e77_g16.jpg', '8b46c1f4-63ed-4cc3-baca-2e58fcfa51a7_g8.jpg', 'd0d01304-b85c-4f0b-98a9-4d5719fbaeaf_g7.jpg']\n",
      "\n",
      "‚ùå Not found: /kaggle/working/corrected_images_fixed\n",
      "\n",
      "üì¶ Zip files found: ['corrected_images.zip']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üîç CELL 9A: FIND WHERE IMAGES ARE STORED\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîç SEARCHING FOR IMAGES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Search in working directory\n",
    "working_dir = '/kaggle/working'\n",
    "print(f\"üìÅ Checking: {working_dir}\")\n",
    "print(\"Contents:\", os.listdir(working_dir))\n",
    "\n",
    "# Look for any folders containing images\n",
    "for item in os.listdir(working_dir):\n",
    "    item_path = os.path.join(working_dir, item)\n",
    "    if os.path.isdir(item_path):\n",
    "        files = list(Path(item_path).glob('*.*'))\n",
    "        if files:\n",
    "            print(f\"\\nüìÇ Folder: {item}\")\n",
    "            print(f\"   Files: {len(files)}\")\n",
    "            print(f\"   Types: {set(f.suffix for f in files)}\")\n",
    "            print(f\"   Sample: {[f.name for f in files[:3]]}\")\n",
    "\n",
    "# Check if corrected_images_fixed exists\n",
    "fixed_folder = '/kaggle/working/corrected_images_fixed'\n",
    "if os.path.exists(fixed_folder):\n",
    "    print(f\"\\n‚úÖ Found: {fixed_folder}\")\n",
    "    print(\"Contents:\", os.listdir(fixed_folder)[:5])\n",
    "else:\n",
    "    print(f\"\\n‚ùå Not found: {fixed_folder}\")\n",
    "\n",
    "# Check for any zip files\n",
    "zip_files = list(Path(working_dir).glob('*.zip'))\n",
    "if zip_files:\n",
    "    print(f\"\\nüì¶ Zip files found: {[f.name for f in zip_files]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d1ff3",
   "metadata": {
    "papermill": {
     "duration": 0.03947,
     "end_time": "2026-02-21T17:38:19.511009",
     "exception": false,
     "start_time": "2026-02-21T17:38:19.471539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üöÄ Run Cell 11 Now If You Want Smaller File Size:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c2edbbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T17:38:19.592828Z",
     "iopub.status.busy": "2026-02-21T17:38:19.592513Z",
     "iopub.status.idle": "2026-02-21T17:39:04.538097Z",
     "shell.execute_reply": "2026-02-21T17:39:04.537475Z"
    },
    "papermill": {
     "duration": 44.989853,
     "end_time": "2026-02-21T17:39:04.539597",
     "exception": false,
     "start_time": "2026-02-21T17:38:19.549744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Compressing file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:41<00:00, 24.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ New size: 363.90 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üóúÔ∏è CELL 11: Compress File to < 500 MB\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"üîÑ Compressing file...\")\n",
    "\n",
    "# Extract images\n",
    "with zipfile.ZipFile('/kaggle/working/corrected_images.zip', 'r') as zipf:\n",
    "    zipf.extractall('/kaggle/working/temp')\n",
    "\n",
    "# Compress with lower quality\n",
    "output_zip = '/kaggle/working/corrected_images_ready.zip'\n",
    "with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for img_path in tqdm(list(Path('/kaggle/working/temp').glob('*.jpg'))):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        _, buffer = cv2.imencode('.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 85])\n",
    "        zipf.writestr(img_path.name, buffer.tobytes())\n",
    "\n",
    "new_size = os.path.getsize(output_zip) / (1024 * 1024)\n",
    "print(f\"‚úÖ New size: {new_size:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 15769099,
     "sourceId": 130932,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31287,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 794.457191,
   "end_time": "2026-02-21T17:39:05.009054",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-21T17:25:50.551863",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
